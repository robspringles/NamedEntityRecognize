{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 CNN 进行命名实体识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入相关模块并设置一些参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import collections\n",
    "import time\n",
    "import os\n",
    "\n",
    "from mxnet import autograd, gluon, nd\n",
    "from mxnet.gluon import nn, rnn, Block\n",
    "from mxnet.contrib import text\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from io import open\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = '<PAD>'\n",
    "NOT = 'N'\n",
    "PAD_NATURE = 'r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "drop_prob = 0.2\n",
    "batch_size = 256\n",
    "learning_rate = 0.01\n",
    "\n",
    "max_seq_len = 30\n",
    "\n",
    "word_vec_size = 200\n",
    "nature_vec_size = 50\n",
    "distance_vec_size = 50\n",
    "num_channels = 10\n",
    "conv_width = word_vec_size + nature_vec_size + distance_vec_size\n",
    "kernels_size_ls = [(2, conv_width), (3, conv_width), (4, conv_width)]\n",
    "padding_ls = None\n",
    "pool_size = (2, 1) \n",
    "output_size = 6\n",
    "distance_size = 2 * max_seq_len - 1\n",
    "\n",
    "test_size_por = 0.1\n",
    "\n",
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义一些辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(max_seq_len):\n",
    "    \"\"\"读取数据\"\"\"\n",
    "    input_tokens = []   # 记录输入 X 的所有词，包含重复\n",
    "    output_tokens = []  # 记录输出 Y 的所有符号，包含重复\n",
    "    nature_tokens = []  # 记录所有词的词性的符号，包含重复\n",
    "    input_seqs = []  # 列表中装的列表，里面的每个列表代表一条输入，填充或截断好了的\n",
    "    output_seqs = []  # 同input_seqs\n",
    "    nature_seqs = []\n",
    "    \n",
    "    with open(\"../data_for_seq2seq/re_cut_lines_word.txt\", 'r') as fx, open(\"../data_for_seq2seq/re_cut_lines_label.txt\", 'r') as fy, open(\"../data_for_seq2seq/re_cut_lines_nature.txt\", 'r') as fn:\n",
    "        word_lines = fx.readlines()\n",
    "        label_lines = fy.readlines()\n",
    "        word_natures = fn.readlines()\n",
    "        \n",
    "        for word_line, lable_line, word_nature in zip(word_lines, label_lines, word_natures):\n",
    "            \n",
    "            input_seq = word_line.strip()\n",
    "            output_seq = lable_line.strip()\n",
    "            nature_seq = word_nature.strip()\n",
    "            \n",
    "            cur_input_tokens = input_seq.split(' ')\n",
    "            cur_output_tokens = output_seq.split(' ')\n",
    "            cur_nature_tokens = nature_seq.split(' ')\n",
    "            \n",
    "            if '' in cur_output_tokens:\n",
    "                continue\n",
    "            \n",
    "            if len(cur_input_tokens) < max_seq_len or len(cur_output_tokens) < max_seq_len or len(cur_nature_tokens) < max_seq_len:\n",
    "                input_tokens.extend(cur_input_tokens)\n",
    "                output_tokens.extend(cur_output_tokens)\n",
    "                nature_tokens.extend(cur_nature_tokens)\n",
    "                \n",
    "                # 添加 PAD 符号使每个序列等长，长度为 max_seq_len\n",
    "                while len(cur_input_tokens) < max_seq_len:\n",
    "                    cur_input_tokens.append(PAD)\n",
    "                    # 把输出也填充到了最大长度\n",
    "                    cur_output_tokens.append(NOT)\n",
    "                    cur_nature_tokens.append(PAD_NATURE)\n",
    "                    \n",
    "                input_seqs.append(cur_input_tokens)                            \n",
    "                output_seqs.append(cur_output_tokens)\n",
    "                nature_seqs.append(cur_nature_tokens)\n",
    "                \n",
    "            else:\n",
    "                cur_input_tokens = cur_input_tokens[0: max_seq_len]\n",
    "                cur_output_tokens = cur_output_tokens[0: max_seq_len]\n",
    "                cur_nature_tokens = cur_nature_tokens[0: max_seq_len]\n",
    "                \n",
    "                input_tokens.extend(cur_input_tokens)\n",
    "                input_seqs.append(cur_input_tokens)\n",
    "                \n",
    "                output_tokens.extend(cur_output_tokens)\n",
    "                output_seqs.append(cur_output_tokens)\n",
    "                \n",
    "                nature_tokens.extend(cur_nature_tokens)\n",
    "                nature_seqs.append(cur_nature_tokens)\n",
    "                \n",
    "        fr_vocab = text.vocab.Vocabulary(collections.Counter(input_tokens), reserved_tokens=[PAD])\n",
    "        print(collections.Counter(output_tokens))\n",
    "        en_vocab = text.vocab.Vocabulary(collections.Counter(output_tokens))\n",
    "        \n",
    "        nature_vocab = text.vocab.Vocabulary(collections.Counter(nature_tokens))\n",
    "    \n",
    "    return fr_vocab, en_vocab, nature_vocab, input_seqs, output_seqs, nature_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cnn_input(word_data, nature, batch_distance, pos):\n",
    "    \"\"\"生成满足模型的输入\"\"\"\n",
    "    x_input = word_data[:, pos]\n",
    "    nature_input = nature[:, pos]\n",
    "    distance_input = batch_distance[:, pos]\n",
    "    \n",
    "    return x_input, nature_input, distance_input   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_scores(y_hat, label):\n",
    "    \"\"\"计算结果的评分指标\"\"\"\n",
    "    # 将预测结果与真实标记都变为一维数组以方便计算\n",
    "    y_hat = y_hat.reshape((-1, ))\n",
    "    label = label.reshape((-1, ))\n",
    "    # average 置为 None，可以返回每个类别的 P R F\n",
    "    p = metrics.precision_score(label, y_hat, average=None)\n",
    "    r = metrics.recall_score(label, y_hat, average=None)\n",
    "    f1 = metrics.f1_score(label, y_hat, average=None)\n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据的预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'N': 7739104, 'C': 626209, 'B': 566764, 'E': 544024, 'I': 153734})\n"
     ]
    }
   ],
   "source": [
    "input_vocab, output_vocab, nature_vocab, input_seqs, output_seqs, nature_seqs = read_data(max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215540"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', 'N', 'C', 'B', 'E', 'I']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_vocab.idx_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nature_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"../data_for_cnn_lstm/X.npy\") and  os.path.exists(\"../data_for_cnn_lstm/Y.npy\") and os.path.exists(\"../data_for_cnn_lstm/nature.npy\"):\n",
    "    print(\"Loading...\")\n",
    "    X = np.load(\"../data_for_cnn_lstm/X.npy\")\n",
    "    Y = np.load(\"../data_for_cnn_lstm/Y.npy\")\n",
    "    nature = np.load(\"../data_for_cnn_lstm/nature.npy\")\n",
    "    print(\"End\")\n",
    "else:\n",
    "    print(\"Converting...\")\n",
    "    X = nd.zeros((len(input_seqs), max_seq_len))\n",
    "    Y = nd.zeros((len(output_seqs), max_seq_len))\n",
    "    nature = nd.zeros((len(nature_seqs), max_seq_len))\n",
    "    \n",
    "    for i in range(len(input_seqs)):\n",
    "        X[i] = nd.array(input_vocab.to_indices(input_seqs[i]))\n",
    "        Y[i] = nd.array(output_vocab.to_indices(output_seqs[i]))\n",
    "        nature[i] = nd.array(nature_vocab.to_indices(nature_seqs[i]))\n",
    "    np.save(\"../data_for_cnn_lstm/X.npy\", X.asnumpy())\n",
    "    np.save(\"../data_for_cnn_lstm/Y.npy\", Y.asnumpy())\n",
    "    np.save(\"../data_for_cnn_lstm/nature.npy\", nature.asnumpy())\n",
    "    print(\"End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((429469, 30), (429469, 30))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nature.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((386522, 30), (386522, 30), (386522, 30)),\n",
       " ((42947, 30), (42947, 30), (42947, 30)))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test, nature_train, nature_test = train_test_split(X, Y, nature, test_size=test_size_por, random_state=33)\n",
    "((X_train.shape, Y_train.shape, nature_train.shape), (X_test.shape, Y_test.shape, nature_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = gluon.data.ArrayDataset(nd.array(X_train, ctx=ctx), nd.array(Y_train, ctx=ctx), nd.array(nature_train, ctx=ctx))\n",
    "data_iter_train = gluon.data.DataLoader(dataset_train, batch_size, shuffle=True, last_batch='rollover')\n",
    "\n",
    "dataset_test = gluon.data.ArrayDataset(nd.array(X_test, ctx=ctx), nd.array(Y_test, ctx=ctx), nd.array(nature_test, ctx=ctx))\n",
    "data_iter_test = gluon.data.DataLoader(dataset_test, batch_size, shuffle=True, last_batch='discard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, Y_train, nature_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(nn.Block):\n",
    "    def __init__(self, vocab_size, word_vec_size, nature_size, nature_vec_size, distance_size, distance_vec_size,\n",
    "                 num_channels, kernels_size_ls, padding_ls, pool_size, output_size,\n",
    "                 drop_prob=0.2,  **kwargs):\n",
    "        super(CNN_Model, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.word_embedding = nn.Embedding(vocab_size, word_vec_size)\n",
    "            self.nature_embedding = nn.Embedding(nature_size, nature_vec_size)\n",
    "            self.distance_embedding = nn.Embedding(distance_size, distance_vec_size)\n",
    "            self.num_channels = num_channels\n",
    "            self.kernels_size_ls = kernels_size_ls\n",
    "            self.conv_ls = []\n",
    "            for kernel_size in kernels_size_ls:\n",
    "                conv = nn.Conv2D(channels=num_channels, kernel_size=kernel_size, activation='relu')\n",
    "                self.register_child(conv)\n",
    "                self.conv_ls.append(conv)\n",
    "            self.max_pool = nn.MaxPool2D(pool_size=pool_size)\n",
    "            self.flatten = nn.Flatten()\n",
    "            self.dense = nn.Dense(output_size)\n",
    "            self.drop = nn.Dropout(drop_prob)\n",
    "        \n",
    "    def forward(self, x_input, nature_input, distance_input):\n",
    "        batch_words_embed = self.word_embedding(x_input)\n",
    "        batch_nature_embed = self.nature_embedding(nature_input)\n",
    "        batch_distance_embed = self.distance_embedding(distance_input)\n",
    "        \n",
    "        # (batch_size, height, width)\n",
    "        batch_data_x = nd.concat(batch_words_embed, batch_nature_embed, batch_distance_embed, dim=2)\n",
    "        # (batch_size, 1, height, width)\n",
    "        batch_data_x = nd.expand_dims(batch_data_x, axis=1)\n",
    "        \n",
    "        conv_pool_result = []\n",
    "        for conv in self.conv_ls:\n",
    "            conv_result = conv(batch_data_x)    # (batch_size, num_channels, out_height, out_width)\n",
    "            pool_result = self.max_pool(conv_result)    # (batch_size, num_channels, new_height, new_width)\n",
    "            pool_result = self.flatten(pool_result)\n",
    "            conv_pool_result.append(pool_result)\n",
    "        # (batch_size, len(kernel_size_ls)*num_channels*new_height,new_width)\n",
    "        conv_pool_result_concated = nd.concat(*conv_pool_result, dim=1)\n",
    "        conv_pool_result_concated = self.drop(conv_pool_result_concated)\n",
    "        output = self.dense(conv_pool_result_concated)\n",
    "        \n",
    "        return output   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建一个输出标签的one-hot矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[1. 0. 0. 0. 0. 0.]\n",
       " [0. 1. 0. 0. 0. 0.]\n",
       " [0. 0. 1. 0. 0. 0.]\n",
       " [0. 0. 0. 1. 0. 0.]\n",
       " [0. 0. 0. 0. 1. 0.]\n",
       " [0. 0. 0. 0. 0. 1.]]\n",
       "<NDArray 6x6 @gpu(0)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_value = nd.array(list(output_vocab.token_to_idx.values()), ctx=ctx)\n",
    "\n",
    "label_one_hot = nd.one_hot(dic_value, dic_value.shape[0])\n",
    "\n",
    "label_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义训练函数，并实例化模型，开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, max_seq_len, label_one_hot, output_vocab, learning_rate, ctx):\n",
    "    \"\"\"训练函数\"\"\"\n",
    "    model.collect_params().initialize(mx.init.Xavier(), ctx=ctx)\n",
    "    \n",
    "    optimizer = gluon.Trainer(model.collect_params(), 'adam',\n",
    "                                      {'learning_rate': learning_rate})\n",
    "\n",
    "    softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss(sparse_label=False)\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    total_loss = []\n",
    "    total_loss_test = []\n",
    "    cate_num = label_one_hot.shape[0]\n",
    "    \n",
    "    for epoch in range(0, epochs):\n",
    "        p = np.zeros((cate_num, ))\n",
    "        r = np.zeros((cate_num, ))\n",
    "        f1 = np.zeros((cate_num, ))      \n",
    "        epoch_loss = 0.0\n",
    "        batch_idx = 0\n",
    "        for x, y, nature in data_iter_train:\n",
    "            batch_preds = []\n",
    "            expand_batch_p = np.zeros((cate_num, ))\n",
    "            expand_batch_r = np.zeros((cate_num, ))\n",
    "            expand_batch_f1 = np.zeros((cate_num, ))\n",
    "            with autograd.record():\n",
    "                batch_loss = nd.array([0], ctx=ctx)              \n",
    "                for word_idx in range(x.shape[1]): \n",
    "                    distance = nd.arange(x.shape[1], ctx=ctx) - word_idx\n",
    "                    distance = distance.reshape((1, -1))\n",
    "                    # batch_distance 尺寸: (batch_size, max_seq_length)\n",
    "                    batch_distance = nd.broadcast_axis(distance, axis=0, size=batch_size)                    \n",
    "                    \n",
    "                    outputs = model(x, nature, batch_distance)\n",
    "                    # preds 代表一个 batch 的第 word_idx 的词的输出，尺寸： (batch_size,)\n",
    "                    preds = nd.argmax(nd.softmax(outputs, axis=1), axis=1)\n",
    "                    \n",
    "                    # 扩展preds 为（batch_size, 1) 并添加入列表\n",
    "                    batch_preds.append(nd.expand_dims(preds, axis=1))              \n",
    "                    y_idx = y[:, word_idx]\n",
    "                    label = nd.take(label_one_hot, y_idx)\n",
    "                    \n",
    "                    batch_loss = batch_loss + nd.mean(softmax_cross_entropy(outputs, label))\n",
    "                \n",
    "            batch_loss.backward()\n",
    "            optimizer.step(batch_size)\n",
    "            \n",
    "            # 将一批的每个词的输出组合,得到一批的模型的输出\n",
    "            # 尺寸为 : (batch_size, max_seq_len)\n",
    "            batch_preds = nd.concat(*batch_preds, dim=1)\n",
    "            epoch_loss += batch_loss.asscalar()                     \n",
    "            \n",
    "            if batch_idx % 500 == 0:\n",
    "                print(\"epoch: {0} , batch: {1}, batch_loss: {2}\".format(epoch, batch_idx, batch_loss.asscalar()))\n",
    "                for example in range(2):\n",
    "                    true_idx = [int(x) for x in list(y[example].asnumpy())]\n",
    "                    pred_idx = [int(x) for x in list(batch_preds[example].asnumpy())]\n",
    "                    \n",
    "                    true_label = output_vocab.to_tokens(true_idx)\n",
    "                    pred_label = output_vocab.to_tokens(pred_idx)\n",
    "                    \n",
    "                    print(\"Sapmle {0} :\".format(example))\n",
    "                    print(\"True label : {0}\".format(true_label))\n",
    "                    print(\"Pred label : {0}\".format(pred_label))                       \n",
    "            \n",
    "            batch_p, batch_r, batch_f1 = cal_scores(batch_preds.asnumpy(), y.asnumpy())\n",
    "            expand_batch_p[0 : batch_p.shape[0]] = batch_p\n",
    "            expand_batch_r[0 : batch_r.shape[0]] = batch_r\n",
    "            expand_batch_f1[0 : batch_f1.shape[0]] = batch_f1          \n",
    "            batch_idx += 1\n",
    "            p += expand_batch_p\n",
    "            r += expand_batch_r\n",
    "            f1 += expand_batch_f1    \n",
    "        \n",
    "        epoch_loss = epoch_loss / batch_idx\n",
    "        p /= batch_idx\n",
    "        r /= batch_idx\n",
    "        f1 /= batch_idx\n",
    "        total_loss.append(epoch_loss)\n",
    "              \n",
    "        # 下面为在测试集上的表现\n",
    "        epoch_loss_test = 0.0\n",
    "        batch_idx_test = 0\n",
    "        p_test = np.zeros((cate_num, ))\n",
    "        r_test = np.zeros((cate_num, ))\n",
    "        f1_test = np.zeros((cate_num, ))\n",
    "        for x_test, y_test, nature_test in data_iter_test:\n",
    "            batch_preds_test = []\n",
    "            expand_batch_p_test = np.zeros((cate_num, ))\n",
    "            expand_batch_r_test = np.zeros((cate_num, ))\n",
    "            expand_batch_f1_test = np.zeros((cate_num, ))\n",
    "            batch_loss_test = nd.array([0], ctx=ctx) \n",
    "            for word_idx_test in range(x_test.shape[1]): \n",
    "                distance_test = nd.arange(x_test.shape[1], ctx=ctx) - word_idx_test\n",
    "                distance_test = distance_test.reshape((1, -1))\n",
    "                batch_distance_test = nd.broadcast_axis(distance_test, axis=0, size=batch_size)                    \n",
    "\n",
    "                outputs_test = model(x_test, nature_test, batch_distance_test) \n",
    "                preds_test = nd.argmax(nd.softmax(outputs_test, axis=1), axis=1)\n",
    "\n",
    "                # 扩展preds 为（test_batch_size, 1) 并添加入列表\n",
    "                batch_preds_test.append(nd.expand_dims(preds_test, axis=1)) \n",
    "                            \n",
    "                y_idx_test = y_test[:, word_idx_test]\n",
    "                label_test = nd.take(label_one_hot, y_idx_test)\n",
    "                    \n",
    "                batch_loss_test = batch_loss_test + nd.mean(softmax_cross_entropy(outputs_test, label_test))\n",
    "            \n",
    "            batch_idx_test += 1\n",
    "            epoch_loss_test += batch_loss_test.asscalar()\n",
    "            batch_preds_test = nd.concat(*batch_preds_test, dim=1)\n",
    "            \n",
    "            # 计算测试集上的 P R F\n",
    "            batch_p_test, batch_r_test, batch_f1_test = cal_scores(batch_preds_test.asnumpy(), y_test.asnumpy())\n",
    "            expand_batch_p_test[0 : batch_p_test.shape[0]] = batch_p_test\n",
    "            expand_batch_r_test[0 : batch_r_test.shape[0]] = batch_r_test\n",
    "            expand_batch_f1_test[0 : batch_f1_test.shape[0]] = batch_f1_test \n",
    "            p_test += expand_batch_p_test\n",
    "            r_test += expand_batch_r_test\n",
    "            f1_test += expand_batch_f1_test\n",
    "        \n",
    "        epoch_loss_test /= batch_idx_test\n",
    "        p_test /= batch_idx_test\n",
    "        r_test /= batch_idx_test\n",
    "        f1_test /= batch_idx_test\n",
    "        total_loss_test.append(epoch_loss_test)\n",
    "        \n",
    "        print(\"epoch: {0} , epoch_loss: {1}, epoch_loss_test: {2}\".format(epoch, epoch_loss, epoch_loss_test))\n",
    "        print(\"*****************************************************\")\n",
    "        print(\"TrainData: \", output_vocab.idx_to_token)\n",
    "        print(\"Precision: \", p)\n",
    "        print(\"Recall   : \", r)\n",
    "        print(\"F1       : \", f1)\n",
    "        print()\n",
    "        print(\"TestData : \", output_vocab.idx_to_token)\n",
    "        print(\"Precision: \", p_test)\n",
    "        print(\"Recall   : \", r_test)\n",
    "        print(\"F1       : \", f1_test)\n",
    "        print(\"*****************************************************\")\n",
    "        print(\"-----------------------------------------------------\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(\"训练结束，用时 {0} 秒\".format(str(end_time-start_time)))\n",
    "    # 绘制每个 epoch 的loss的变化曲线图\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.plot(range(epochs), total_loss, 'b', label='train_loss')\n",
    "    plt.plot(range(epochs), total_loss_test, 'g', label='test_loss')\n",
    "    plt.legend()\n",
    "    plt.show()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_Model(len(input_vocab), word_vec_size, len(nature_vocab), nature_vec_size, distance_size, distance_vec_size,\n",
    "                 num_channels, kernels_size_ls, padding_ls, pool_size, output_size, drop_prob=drop_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\developtool\\python\\lib\\site-packages\\mxnet\\gluon\\block.py:228: UserWarning: \"CNN_Model.conv_ls\" is a container with Blocks. Note that Blocks inside the list, tuple or dict will not be registered automatically. Make sure to register them using register_child() or switching to nn.Sequential/nn.HybridSequential instead. \n",
      "  .format(name=self.__class__.__name__ + \".\" + k))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 , batch: 0, batch_loss: 54.49553680419922\n",
      "Sapmle 0 :\n",
      "True label : ['C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['<unk>', '<unk>', 'I', 'I', 'I', 'I', 'I', '<unk>', 'I', 'I', 'I', 'I', 'I', 'E', 'I', 'I', 'I', '<unk>', 'I', 'I', 'B', 'E', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I']\n",
      "Sapmle 1 :\n",
      "True label : ['C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['I', 'I', 'I', 'I', 'I', 'I', 'I', '<unk>', 'I', '<unk>', 'B', 'I', 'I', 'I', '<unk>', 'I', 'I', '<unk>', '<unk>', 'B', 'B', 'I', '<unk>', 'B', 'I', 'I', 'B', '<unk>', 'B', '<unk>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\developtool\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "c:\\developtool\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "c:\\developtool\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\developtool\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 , batch: 500, batch_loss: 6.171684265136719\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'B', 'E', 'N', 'B', 'E', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 0 , batch: 1000, batch_loss: 5.232990264892578\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C']\n",
      "Pred label : ['N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 0 , batch: 1500, batch_loss: 4.969158172607422\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 0 , epoch_loss: 7.036620028529284, epoch_loss_test: 4.6973240418348485\n",
      "*****************************************************\n",
      "TrainData:  ['<unk>', 'N', 'C', 'B', 'E', 'I']\n",
      "Precision:  [9.41303063e-01 8.18357977e-01 7.09037506e-01 7.09574091e-01\n",
      " 6.51512434e-01 7.43692732e-06]\n",
      "Recall   :  [9.83394061e-01 8.14655769e-01 4.91588225e-01 4.65783776e-01\n",
      " 4.28598319e-01 2.38053877e-04]\n",
      "F1       :  [9.61642857e-01 8.09143077e-01 5.75731603e-01 5.56629377e-01\n",
      " 5.08126978e-01 1.44232643e-05]\n",
      "\n",
      "TestData :  ['<unk>', 'N', 'C', 'B', 'E', 'I']\n",
      "Precision:  [0.95763244 0.90490136 0.84737389 0.83377    0.83727821 0.        ]\n",
      "Recall   :  [0.98781816 0.92750591 0.60205746 0.60625507 0.54325899 0.        ]\n",
      "F1       :  [0.97248713 0.91591276 0.70358564 0.70167386 0.65688715 0.        ]\n",
      "*****************************************************\n",
      "-----------------------------------------------------\n",
      "epoch: 1 , batch: 0, batch_loss: 4.89638614654541\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['B', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['B', 'I', 'E', 'B', 'I', 'I', 'I', 'E', 'N', 'N', 'N', 'N', 'N', 'B', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'B', 'E', 'N']\n",
      "Pred label : ['B', 'B', 'E', 'N', 'N', 'N', 'N', 'E', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'B', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 1 , batch: 500, batch_loss: 4.88546895980835\n",
      "Sapmle 0 :\n",
      "True label : ['B', 'E', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'B', 'I', 'E', 'C', 'N', 'B']\n",
      "Pred label : ['B', 'E', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 1 , batch: 1000, batch_loss: 4.271523952484131\n",
      "Sapmle 0 :\n",
      "True label : ['B', 'I', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['C', 'I', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['C', 'N', 'N', 'C', 'N', 'C', 'N', 'C', 'C', 'N', 'N', 'N', 'C', 'N', 'C', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E']\n",
      "Pred label : ['C', 'N', 'N', 'C', 'N', 'C', 'N', 'C', 'C', 'N', 'N', 'N', 'C', 'N', 'C', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 1 , batch: 1500, batch_loss: 4.562465667724609\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 1 , epoch_loss: 4.347256940090103, epoch_loss_test: 4.28720749923569\n",
      "*****************************************************\n",
      "TrainData:  ['<unk>', 'N', 'C', 'B', 'E', 'I']\n",
      "Precision:  [0.96571081 0.92025026 0.82425385 0.81254933 0.78201644 0.        ]\n",
      "Recall   :  [0.9857169  0.93645544 0.68359687 0.64954915 0.61110887 0.        ]\n",
      "F1       :  [0.97560409 0.92813418 0.74668748 0.72110431 0.6835045  0.        ]\n",
      "\n",
      "TestData :  ['<unk>', 'N', 'C', 'B', 'E', 'I']\n",
      "Precision:  [0.96723376 0.90636826 0.84652837 0.83422079 0.85769609 0.        ]\n",
      "Recall   :  [0.98659954 0.9423975  0.70073605 0.67643032 0.59634813 0.        ]\n",
      "F1       :  [0.97681709 0.92390448 0.76643893 0.74674106 0.70175925 0.        ]\n",
      "*****************************************************\n",
      "-----------------------------------------------------\n",
      "epoch: 2 , batch: 0, batch_loss: 4.663608551025391\n",
      "Sapmle 0 :\n",
      "True label : ['C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 2 , batch: 500, batch_loss: 3.656005859375\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'C', 'N', 'N', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'B', 'I', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'I', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['C', 'B', 'I', 'E', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['C', 'B', 'I', 'E', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'N']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 , batch: 1000, batch_loss: 3.5932822227478027\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 2 , batch: 1500, batch_loss: 4.0118327140808105\n",
      "Sapmle 0 :\n",
      "True label : ['B', 'I', 'E', 'B', 'I', 'I', 'I', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['B', 'I', 'E', 'B', 'I', 'E', 'N', 'N', 'B', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['C', 'N', 'B', 'I', 'I', 'I', 'I', 'I', 'E', 'N', 'C', 'N', 'N', 'N', 'N', 'B', 'I', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['C', 'N', 'B', 'I', 'I', 'N', 'I', 'I', 'E', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'I', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 2 , epoch_loss: 3.688760936023384, epoch_loss_test: 4.294972032843949\n",
      "*****************************************************\n",
      "TrainData:  ['<unk>', 'N', 'C', 'B', 'E', 'I']\n",
      "Precision:  [0.97148562 0.93669302 0.84665859 0.82860648 0.80680885 0.        ]\n",
      "Recall   :  [0.98711147 0.94403401 0.73729788 0.70361929 0.66319872 0.        ]\n",
      "F1       :  [0.97923094 0.94021821 0.78769399 0.76030744 0.7256546  0.        ]\n",
      "\n",
      "TestData :  ['<unk>', 'N', 'C', 'B', 'E', 'I']\n",
      "Precision:  [0.97011272 0.9210884  0.85744868 0.83977128 0.80775268 0.        ]\n",
      "Recall   :  [0.98666229 0.93359119 0.72807035 0.70490304 0.67535159 0.        ]\n",
      "F1       :  [0.97831396 0.92716424 0.78719864 0.76611795 0.73378913 0.        ]\n",
      "*****************************************************\n",
      "-----------------------------------------------------\n",
      "epoch: 3 , batch: 0, batch_loss: 3.274446725845337\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'C', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'C', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 3 , batch: 500, batch_loss: 2.9705567359924316\n",
      "Sapmle 0 :\n",
      "True label : ['B', 'I', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['B', 'I', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 3 , batch: 1000, batch_loss: 3.223472833633423\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'I', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'N', 'B', 'I', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 3 , batch: 1500, batch_loss: 3.4103987216949463\n",
      "Sapmle 0 :\n",
      "True label : ['C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 3 , epoch_loss: 3.3581829746827383, epoch_loss_test: 4.298820142974397\n",
      "*****************************************************\n",
      "TrainData:  ['<unk>', 'N', 'C', 'B', 'E', 'I']\n",
      "Precision:  [0.97432293 0.94378967 0.85838365 0.83859459 0.81671811 0.        ]\n",
      "Recall   :  [0.98791766 0.94668659 0.76426907 0.73060255 0.68996597 0.        ]\n",
      "F1       :  [0.981069   0.94512534 0.80816937 0.78029869 0.74608094 0.        ]\n",
      "\n",
      "TestData :  ['<unk>', 'N', 'C', 'B', 'E', 'I']\n",
      "Precision:  [0.97041601 0.93171377 0.85169241 0.84551173 0.84071202 0.        ]\n",
      "Recall   :  [0.98748563 0.92296246 0.74479383 0.71648846 0.64685099 0.        ]\n",
      "F1       :  [0.97887333 0.92716582 0.79436382 0.77537022 0.72914387 0.        ]\n",
      "*****************************************************\n",
      "-----------------------------------------------------\n",
      "epoch: 4 , batch: 0, batch_loss: 3.2826685905456543\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'C', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'B', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'C', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'C', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'C', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 4 , batch: 500, batch_loss: 2.7939984798431396\n",
      "Sapmle 0 :\n",
      "True label : ['C', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'B', 'E', 'B', 'E', 'N']\n",
      "Pred label : ['C', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'B', 'E', 'B', 'E', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['C', 'B', 'E', 'B', 'E', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['C', 'B', 'E', 'B', 'E', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 4 , batch: 1000, batch_loss: 3.4830641746520996\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'C', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'I', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'C', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 , batch: 1500, batch_loss: 3.2860941886901855\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['B', 'I', 'E', 'C', 'C', 'N', 'C', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'B', 'I', 'I', 'I', 'I', 'I', 'E', 'N']\n",
      "Pred label : ['B', 'I', 'E', 'C', 'C', 'N', 'C', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'E', 'N', 'N', 'E', 'E', 'N']\n",
      "epoch: 4 , epoch_loss: 3.1475345051051766, epoch_loss_test: 4.418062802560315\n",
      "*****************************************************\n",
      "TrainData:  ['<unk>', 'N', 'C', 'B', 'E', 'I']\n",
      "Precision:  [0.97604372 0.9476412  0.86584428 0.84593907 0.82263123 0.        ]\n",
      "Recall   :  [0.98849406 0.94840462 0.77941784 0.74759809 0.70803485 0.        ]\n",
      "F1       :  [0.98222538 0.94792552 0.81994276 0.79319138 0.75922762 0.        ]\n",
      "\n",
      "TestData :  ['<unk>', 'N', 'C', 'B', 'E', 'I']\n",
      "Precision:  [0.97025454 0.91441942 0.86810242 0.86703662 0.84597649 0.        ]\n",
      "Recall   :  [0.98813891 0.93933001 0.73324251 0.70396978 0.67191889 0.        ]\n",
      "F1       :  [0.97911244 0.92657497 0.79472814 0.77674626 0.74748491 0.        ]\n",
      "*****************************************************\n",
      "-----------------------------------------------------\n",
      "epoch: 5 , batch: 0, batch_loss: 3.2070987224578857\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'B', 'E', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'B', 'E', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['C', 'N', 'N', 'N', 'B', 'I', 'E', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['C', 'N', 'N', 'N', 'C', 'I', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 5 , batch: 500, batch_loss: 3.167546510696411\n",
      "Sapmle 0 :\n",
      "True label : ['B', 'E', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'C', 'B', 'E', 'B', 'E', 'N', 'N', 'N', 'B', 'B', 'E', 'C', 'N', 'N', 'N', 'C']\n",
      "Pred label : ['B', 'I', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'B', 'B', 'E', 'B', 'E', 'N', 'E', 'N', 'B', 'B', 'E', 'C', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 5 , batch: 1000, batch_loss: 3.5015599727630615\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 5 , batch: 1500, batch_loss: 2.9308600425720215\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'B', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 5 , epoch_loss: 2.998031358055721, epoch_loss_test: 4.490364690026837\n",
      "*****************************************************\n",
      "TrainData:  ['<unk>', 'N', 'C', 'B', 'E', 'I']\n",
      "Precision:  [0.97725081 0.9509753  0.87214416 0.85183212 0.83005092 0.        ]\n",
      "Recall   :  [0.98899714 0.94942599 0.79174004 0.75927577 0.72148854 0.        ]\n",
      "F1       :  [0.98308559 0.95010575 0.82962423 0.80244586 0.77022087 0.        ]\n",
      "\n",
      "TestData :  ['<unk>', 'N', 'C', 'B', 'E', 'I']\n",
      "Precision:  [0.97389631 0.9209117  0.84835726 0.8323563  0.84771852 0.        ]\n",
      "Recall   :  [0.98558747 0.93613793 0.76916421 0.74772934 0.65255926 0.        ]\n",
      "F1       :  [0.97970381 0.9283231  0.80657658 0.78748811 0.73579961 0.        ]\n",
      "*****************************************************\n",
      "-----------------------------------------------------\n",
      "epoch: 6 , batch: 0, batch_loss: 2.945309638977051\n",
      "Sapmle 0 :\n",
      "True label : ['B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 6 , batch: 500, batch_loss: 3.20717191696167\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'C', 'N', 'B', 'I', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'C', 'N', 'B', 'I', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['B', 'I', 'E', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['B', 'I', 'E', 'N', 'N', 'C', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N']\n",
      "epoch: 6 , batch: 1000, batch_loss: 2.851318597793579\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'B', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'B', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 6 , batch: 1500, batch_loss: 2.9984934329986572\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'C', 'N', 'N', 'N', 'C', 'N', 'C', 'C', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'C', 'N', 'N', 'N', 'C', 'N', 'C', 'C', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'B', 'E', 'N', 'N', 'B', 'N', 'N', 'C', 'N', 'N', 'E', 'N', 'N', 'N', 'N', 'N']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 , epoch_loss: 2.8849542482235795, epoch_loss_test: 4.659588041419754\n",
      "*****************************************************\n",
      "TrainData:  ['<unk>', 'N', 'C', 'B', 'E', 'I']\n",
      "Precision:  [0.97815758 0.95378567 0.87634387 0.85550504 0.83323875 0.        ]\n",
      "Recall   :  [0.98930312 0.95042597 0.79977805 0.7689565  0.73043709 0.        ]\n",
      "F1       :  [0.98369557 0.95201924 0.83593423 0.80947276 0.77678966 0.        ]\n",
      "\n",
      "TestData :  ['<unk>', 'N', 'C', 'B', 'E', 'I']\n",
      "Precision:  [0.97285076 0.92363768 0.86983764 0.8385256  0.86425907 0.        ]\n",
      "Recall   :  [0.98714177 0.93702802 0.7552957  0.74244909 0.66523226 0.        ]\n",
      "F1       :  [0.97994156 0.93019036 0.8082692  0.78733821 0.74975989 0.        ]\n",
      "*****************************************************\n",
      "-----------------------------------------------------\n",
      "epoch: 7 , batch: 0, batch_loss: 2.674131155014038\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'C', 'N', 'N', 'N', 'C', 'C', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'C', 'N', 'N', 'N', 'C', 'C', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 7 , batch: 500, batch_loss: 3.164931297302246\n",
      "Sapmle 0 :\n",
      "True label : ['C', 'N', 'E', 'N', 'N', 'N', 'N', 'B', 'I', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['C', 'N', 'E', 'N', 'N', 'N', 'B', 'E', 'I', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 7 , batch: 1000, batch_loss: 2.8521337509155273\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 7 , batch: 1500, batch_loss: 3.187279224395752\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'B', 'E', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 7 , epoch_loss: 2.8024495547180934, epoch_loss_test: 4.806816473692477\n",
      "*****************************************************\n",
      "TrainData:  ['<unk>', 'N', 'C', 'B', 'E', 'I']\n",
      "Precision:  [0.9788714  0.95523125 0.87898544 0.85851766 0.83514449 0.        ]\n",
      "Recall   :  [0.98953651 0.9506453  0.80706513 0.77537539 0.73642983 0.        ]\n",
      "F1       :  [0.98417201 0.95284591 0.84113753 0.81440347 0.78113305 0.        ]\n",
      "\n",
      "TestData :  ['<unk>', 'N', 'C', 'B', 'E', 'I']\n",
      "Precision:  [0.97141313 0.92248512 0.88238265 0.85610162 0.85879001 0.        ]\n",
      "Recall   :  [0.98856803 0.93668925 0.74245266 0.72833062 0.66477474 0.        ]\n",
      "F1       :  [0.97991247 0.92943804 0.80611616 0.78672522 0.74728018 0.        ]\n",
      "*****************************************************\n",
      "-----------------------------------------------------\n",
      "epoch: 8 , batch: 0, batch_loss: 2.8885467052459717\n",
      "Sapmle 0 :\n",
      "True label : ['B', 'I', 'I', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'B', 'E']\n",
      "Pred label : ['B', 'I', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['C', 'N', 'C', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['C', 'N', 'C', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 8 , batch: 500, batch_loss: 2.58581805229187\n",
      "Sapmle 0 :\n",
      "True label : ['C', 'N', 'N', 'C', 'N', 'N', 'C', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'B', 'I', 'I', 'I', 'E', 'N', 'N', 'N', 'N', 'C', 'N']\n",
      "Pred label : ['C', 'N', 'N', 'C', 'N', 'N', 'C', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'B', 'I', 'I', 'I', 'E', 'N', 'N', 'N', 'N', 'C', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 8 , batch: 1000, batch_loss: 2.664288282394409\n",
      "Sapmle 0 :\n",
      "True label : ['C', 'C', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['C', 'C', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'B', 'N', 'B', 'E', 'N', 'N', 'B', 'E', 'N', 'N', 'B', 'E', 'N', 'N', 'B', 'E', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'B', 'N', 'N', 'N', 'B', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'E', 'N']\n",
      "epoch: 8 , batch: 1500, batch_loss: 3.0068135261535645\n",
      "Sapmle 0 :\n",
      "True label : ['C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 8 , epoch_loss: 2.726489119734985, epoch_loss_test: 4.793031112876481\n",
      "*****************************************************\n",
      "TrainData:  ['<unk>', 'N', 'C', 'B', 'E', 'I']\n",
      "Precision:  [0.97940378 0.95668717 0.88208162 0.86197828 0.83806886 0.        ]\n",
      "Recall   :  [0.98979755 0.95141306 0.81229182 0.78078663 0.74277134 0.        ]\n",
      "F1       :  [0.98457049 0.95395973 0.8454305  0.81898105 0.78604024 0.        ]\n",
      "\n",
      "TestData :  ['<unk>', 'N', 'C', 'B', 'E', 'I']\n",
      "Precision:  [0.973625   0.92842217 0.8633426  0.84946211 0.84607286 0.        ]\n",
      "Recall   :  [0.98727039 0.93256048 0.76641    0.74761026 0.68117649 0.        ]\n",
      "F1       :  [0.98039658 0.93035433 0.81170013 0.79493092 0.75294116 0.        ]\n",
      "*****************************************************\n",
      "-----------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 , batch: 0, batch_loss: 2.7727839946746826\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'C', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'C', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 9 , batch: 500, batch_loss: 2.8174490928649902\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 9 , batch: 1000, batch_loss: 2.6680986881256104\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'C', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 9 , batch: 1500, batch_loss: 2.3139946460723877\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'C', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'I', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'I', 'E', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'C', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'I', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['C', 'N', 'N', 'N', 'N', 'B', 'I', 'E', 'N', 'N', 'N', 'B', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N']\n",
      "Pred label : ['C', 'N', 'N', 'N', 'N', 'B', 'I', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N']\n",
      "epoch: 9 , epoch_loss: 2.678010214875076, epoch_loss_test: 4.9205332259218135\n",
      "*****************************************************\n",
      "TrainData:  ['<unk>', 'N', 'C', 'B', 'E', 'I']\n",
      "Precision:  [0.97979458 0.95763573 0.8840484  0.8631937  0.84174871 0.        ]\n",
      "Recall   :  [0.98994504 0.95162024 0.81513827 0.78539171 0.74804638 0.        ]\n",
      "F1       :  [0.98484072 0.95454407 0.84787647 0.82205979 0.79067707 0.        ]\n",
      "\n",
      "TestData :  ['<unk>', 'N', 'C', 'B', 'E', 'I']\n",
      "Precision:  [0.97442812 0.9303269  0.85239349 0.8464485  0.82694533 0.        ]\n",
      "Recall   :  [0.98636071 0.93058791 0.7759792  0.7512606  0.69817524 0.        ]\n",
      "F1       :  [0.98035512 0.93035546 0.81213719 0.79575821 0.75545664 0.        ]\n",
      "*****************************************************\n",
      "-----------------------------------------------------\n",
      "训练结束，用时 6465.2551009655 秒\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAIABJREFUeJzt3Xt8VNW99/HPLyEk4X4NhGsod0GEJEIRQREleDlW7Wm1rUdpazn6slafPniUPtpTPbbS6mmp1Wpti8fjtR4s1tNaQfGCykUJIIZbAQUTCCbcCRDIZT1/rMkNEghhJnsy832/XvPKnpk9e/+Y2u/es/baa5lzDhERiX0JQRcgIiLNQ4EvIhInFPgiInFCgS8iEicU+CIicUKBLyISJxT4IiJxQoEvccnMtprZxUHXIdKcFPgiInFCgS9Si5l9z8w2m9keM3vVzHqFXjcz+5WZFZnZfjNbY2YjQ+9dZmbrzOygmW03s5nB/itE6qfAFwkxs4uAB4GvA+nANuDF0NtTgUnAEKATcC2wO/TeH4F/dc61B0YCbzVj2SKN1iroAkSiyLeAuc65lQBmNgvYa2YZQBnQHhgGfOicW1/rc2XAWWb2sXNuL7C3WasWaSSd4YvU6IU/qwfAOVeCP4vv7Zx7C3gUeAz4wsyeNLMOoVW/ClwGbDOzd81sfDPXLdIoCnyRGjuA/lVPzKwt0BXYDuCce8Q5lwWMwDft3Bl6/SPn3FeANOAV4KVmrlukURT4Es+SzCyl6oEP6m+b2WgzSwZ+Bix3zm01s3PNbJyZJQGHgFKgwsxam9m3zKyjc64MOABUBPYvEjkJBb7Es9eAI7UeE4F7gZeBQmAgcF1o3Q7A7/Ht89vwTT0Ph977F2CrmR0Abgaub6b6RU6LaQIUEZH4oDN8EZE4ocAXEYkTCnwRkTihwBcRiRNRdadtt27dXEZGRtBliIi0GLm5ubucc90bs25UBX5GRgYrVqwIugwRkRbDzLadei1PTToiInFCgS8iEicU+CIicSKq2vBFJPaUlZVRUFBAaWlp0KW0aCkpKfTp04ekpKQmb0OBLyIRVVBQQPv27cnIyMDMgi6nRXLOsXv3bgoKChgwYECTt6MmHRGJqNLSUrp27aqwPwNmRteuXc/4V5ICX0QiTmF/5sLxHUYs8M1sqJmtrvU4YGZ3hHs/paXw0EPw5pvh3rKISGyJWBu+c24jMBrAzBLxswbND/d+Wrf2gX/JJXDxxeHeuohI7GiuJp0pwBbnXKPvCGushASYOhUWLoTKynBvXURaun379vHb3/72tD932WWXsW/fvtP+3PTp05k3b95pf645NFfgXwe8UN8bZjbDzFaY2Yri4uImbTwnB3btglWrzqREEYlFDQV+RcXJZ6J87bXX6NSpU6TKCkTEu2WaWWvgSmBWfe87554EngTIzs5u0vRbU6f6vwsWQFZWk8oUkWZwxx2wenV4tzl6NMyZ0/D7d999N1u2bGH06NEkJSXRrl070tPTWb16NevWreOqq64iPz+f0tJSbr/9dmbMmAHUjO1VUlLCpZdeyvnnn8+SJUvo3bs3f/nLX0hNTT1lbYsWLWLmzJmUl5dz7rnn8vjjj5OcnMzdd9/Nq6++SqtWrZg6dSoPP/ww//M//8N9991HYmIiHTt2ZPHixeH6iqo1xxn+pcBK59wXkdpBjx7+f/QFCyK1BxFpqWbPns3AgQNZvXo1Dz30EB9++CE//elPWbduHQBz584lNzeXFStW8Mgjj7B79+4TtrFp0yZuvfVW1q5dS6dOnXj55ZdPud/S0lKmT5/On/70Jz755BPKy8t5/PHH2bNnD/Pnz2ft2rWsWbOGe+65B4D777+fBQsW8PHHH/Pqq6+G90sIaY4br75BA8054ZSTA//5n3DgAHToEOm9iUhTnOxMvLmMHTu2zs1LjzzyCPPn+/4k+fn5bNq0ia5du9b5zIABAxg9ejQAWVlZbN269ZT72bhxIwMGDGDIkCEA3HjjjTz22GN8//vfJyUlhZtuuonLL7+cK664AoAJEyYwffp0vv71r3PNNdeE4596goie4ZtZG+AS4M+R3A/4wC8vh7ffjvSeRKQla9u2bfXyO++8w5tvvsnSpUv5+OOPGTNmTL03NyUnJ1cvJyYmUl5efsr9OFd/C3WrVq348MMP+epXv8orr7zCtGnTAHjiiSd44IEHyM/PZ/To0fX+0jhTEQ1859xh51xX59z+SO4HYMIEaNtWzToiUlf79u05ePBgve/t37+fzp0706ZNGzZs2MCyZcvCtt9hw4axdetWNm/eDMAzzzzDBRdcQElJCfv37+eyyy5jzpw5rA5d1NiyZQvjxo3j/vvvp1u3buTn54etlioxM5ZO69YwebICX0Tq6tq1KxMmTGDkyJGkpqbSo0eP6vemTZvGE088wahRoxg6dChf/vKXw7bflJQUnnrqKb72ta9VX7S9+eab2bNnD1/5ylcoLS3FOcevfvUrAO688042bdqEc44pU6ZwzjnnhK2WKtbQz44gZGdnuzOZ8erRR+G222DTJhg0KIyFiUiTrV+/nuHDhwddRkyo77s0s1znXHZjPh9TY+nk5Pi/CxcGW4eISDSKqcAfNAgGDFCzjohE3q233sro0aPrPJ566qmgyzqpmGnDBzDzZ/nPPgvHjvl2fRGRSHjssceCLuG0xdQZPvjALymBpUuDrkREJLrEXOBfdBG0aqVmHRGR48Vc4HfoAOPHK/BFRI4Xc4EPvlln5UooKgq6EhGR6BGzgQ/wxhvB1iEiwWvqePgAc+bM4fDhwyddJyMjg127djVp+80tJgM/MxO6dVOzjohEPvBbkpjqllklIcFPeVg1C1ZCTB7WRFqeO16/g9U7wzsg/uieo5kzreFhOGuPh3/JJZeQlpbGSy+9xNGjR7n66qu57777OHToEF//+tcpKCigoqKCe++9ly+++IIdO3YwefJkunXrxtuNGJnxl7/8JXPnzgXgpptu4o477qh329dee229Y+JHWkwGPvhmnRdegDVr/Fj5IhKfZs+eTV5eHqtXr2bhwoXMmzePDz/8EOccV155JYsXL6a4uJhevXrxt7/9DfCDqnXs2JFf/vKXvP3223Tr1u2U+8nNzeWpp55i+fLlOOcYN24cF1xwAZ9++ukJ264aE3/Dhg2YWZOmUmyKmA382rNgKfBFosPJzsSbw8KFC1m4cCFjxowBoKSkhE2bNjFx4kRmzpzJXXfdxRVXXMHEiRNPe9vvv/8+V199dfXwy9dccw3vvfce06ZNO2Hb5eXl9Y6JH2kx29iRng6jRqkdX0RqOOeYNWsWq1evZvXq1WzevJnvfve7DBkyhNzcXM4++2xmzZrF/fff36Rt16e+bTc0Jn6kxWzgg2/Wef99f+etiMSn2uPh5+TkMHfuXEpCobB9+3aKiorYsWMHbdq04frrr2fmzJmsXLnyhM+eyqRJk3jllVc4fPgwhw4dYv78+UycOLHebTc0Jn6kxWyTDvjAf+gheOcdaKZfTCISZWqPh3/ppZfyzW9+k/HjxwPQrl07nn32WTZv3sydd95JQkICSUlJPP744wDMmDGDSy+9lPT09FNetM3MzGT69OmMHTsW8Bdtx4wZw4IFC07Y9sGDB+sdEz/SYmo8/OMdPQpdusB3vgO/+U3YNisip0Hj4YePxsM/ieRkuPBCteOLiECMN+mAb9Z57TX47DM/Vr6ISFOMGzeOo0eP1nntmWee4eyzzw6ootMX84Ffu3vmzTcHW4tIvHLOYWZBl3FGli9fHuj+w9H8HtNNOgBDh0K/fmrWEQlKSkoKu3fvDktgxSvnHLt37yYlJeWMthPzZ/hVs2C9+CKUlUFSUtAVicSXPn36UFBQQHFxcdCltGgpKSn06dPnjLYR84EPPvB//3tYtgyacAOdiJyBpKQkBugCWlSI+SYdgClTIDFRzToiEt/iIvA7dYJx4xT4IhLf4iLwwTfr5OZCC5mnQEQk7OIq8J3TLFgiEr/iJvCzs/0wC2rWEZF4FTeBn5gIF1/sZ8FSd2ARiUdxE/jgm3UKC+GTT4KuRESk+cVV4NceZkFEJN7EVeD36QMjRijwRSQ+xVXgg2/Wee89OHQo6EpERJpXXAb+sWPw7rtBVyIi0rziLvAnToSUFDXriEj8iWjgm1knM5tnZhvMbL2ZjY/k/hojNRUuuECBLyLxJ9Jn+L8GXnfODQPOAdZHeH+NkpMDGzfCtm1BVyIi0nwiFvhm1gGYBPwRwDl3zDm3L1L7Ox05Of6vzvJFJJ5E8gz/S0Ax8JSZrTKzP5hZ2+NXMrMZZrbCzFY01wQJw4f7LpoKfBGJJ5EM/FZAJvC4c24McAi4+/iVnHNPOueynXPZ3bt3j2A5NapmwVq0CMrLm2WXIiKBi2TgFwAFzrmqmX/n4Q8AUSEnB/bvh4DnJRYRaTYRC3zn3E4g38yGhl6aAqyL1P5O18UXQ0KCmnVEJH5EupfObcBzZrYGGA38LML7a7TOnWHsWAW+iMSPiAa+c251qH1+lHPuKufc3kju73Tl5MBHH8Hu3UFXIiISeXF3p21tVbNgLVoUdCUiIpEX14F/7rl+gnM164hIPIjrwG/Vyl+8XbBAs2CJSOyL68AH36yzfTusi5r+QyIikaHA1zALIhIn4j7w+/b1Qy0o8EUk1sV94IM/y1+8GI4cCboSEZHIUeDjA7+01Ie+iEisUuADkyZBcrKadUQktinwgTZtfOgr8EUklinwQ3JyfNfM/PygKxERiQwFfkhV98yFC4OtQ0QkUhT4ISNGQO/eatYRkdilwA8xg6lT4c03oaIi6GpERMJPgV/L1Kmwd68fMllEJNYo8Gu55BJ/pq9mHRGJRQr8Wrp2hexsBb6IxCYF/nFycvzE5nujam4uEZEzp8A/Tk4OVFZqFiwRiT0K/OOMGwcdOqhZR0RijwL/OElJMGWKZsESkdijwK9HTo4fYmHDhqArEREJHwV+PTQLlojEIgV+PTIyYMgQBb6IxBYFfgNycuDdd/3EKCIisUCB34CcHD/l4XvvBV2JiEh4KPAbcOGF0Lq1mnVEJHYo8BvQti2cf74CX0RihwL/JHJyIC8Ptm8PuhIRkTOnwD8JzYIlIrFEgX8So0ZBz55q1hGR2KDAP4mqWbDeeEOzYIlIy6fAP4WcHNizB3Jzg65EROTMKPBPQbNgiUisUOCfQvfukJmpwBeRlu+UgW9mPczsj2b299Dzs8zsu5EvLXrk5MCyZbB/f9CViIg0XWPO8P8LWAD0Cj3/B3BHYzZuZlvN7BMzW21mK5pWYvBycvxFW82CJSItWWMCv5tz7iWgEsA5Vw6cTp+Vyc650c657KYUGA3Gj4f27dWsIyItW2MC/5CZdQUcgJl9GYirxo2kJLjoIs2CJSItW2MC/4fAq8BAM/sA+G/gtkZu3wELzSzXzGY0scaokJMD27bBP/4RdCUiIk3T6lQrOOdWmtkFwFDAgI3OubJGbn+Cc26HmaUBb5jZBufc4torhA4EMwD69et3etU3o9qzYA0dGmwtIiJNYe4UbRRmdkN9rzvn/vu0dmT2E6DEOfdwQ+tkZ2e7FSui99ru4MF+Jqy//S3oSkREPDPLbew10lOe4QPn1lpOAaYAK/FNOycroi2Q4Jw7GFqeCtzfmKKiVU4OPPUUHD0KyclBVyMiLZVzjp0lO1lbvJa8ojwOHj3IvRfcG/H9NqZJp057vZl1BJ5pxLZ7APPNrGo/zzvnXm9KkdEiJwceeww++MBfxBUROZU9R/aQV5TH2iIf7nnFeeQV5bHnyJ7qdTI6ZXDPpHsI5WXENOYM/3iHgcGnWsk59ylwThO2H7UmT/Y9dhYsUOCLSF0Hjx5kXfE6H+pFedVn74UlhdXrdEzuyMi0kXztrK8xovsIRqaNZETaCNLapjVLjacMfDP7X0JdMvG9es4CXopkUdGqXTuYMMEH/s9/HnQ1IhKE0vJSNuzaUB3sVeG+dd/W6nVSW6UyIm0EOYNyGNndh/rItJH0bt874mfxJ9OYM/zaF1nLgW3OuYII1RP1cnJg1izYudOPlS8isamsoozNezbXBHuoKWbzns1UukoAkhKSGNZtGOP7jOd7md/zZ+zdRzCg8wASLPqGKmtMG/67zVFIS1EV+AsXwg319l8SkYYcLT9KXlEe63etxzlHq4RWJCUmkZSQRFJikn8eWk5KSDqt9xMTEptUU6Wr5LO9n9VphskrymPDrg2UVfoe6AmWwOAugxmZNpLrRlzHyLSRjEwbyaAug0hKTArnVxRRDQa+mR2kpimnzluAc851iFhVUeyccyAtzTfrKPBFGlZaXsqaL9awsnAluTtyyS3MJa8orzpEw82wkx4g6jtYHK04yoZdGzhcdrh6OxmdMhiZNpLLBl9WHezDug0jpVVKROpuTg0GvnOufXMW0lIkJPhZsF5/HSor/XOReHe47DAf7/yY3MJcH/CFuawtWkuF88NudUntQmZ6Jj8c/0My0zMZ1WMUSQlJlFWWUVZRRnllefVyWWXoeWj5jN8/7nnt5Y4JHbmg/wXVTTFndT+L9smxG32N7qUTulu2+hDnnPs8IhW1ADk58OyzsGoVZGUFXY1I8yo5VsLqnavJ3ZHLyp3+7H39rvXV7drd23Qnq1cWVwy+gqxeWWSmZ9K/Y/9AL1aK15heOlcC/4kfHrkI6A+sB0ZEtrToNXWq/7tggQJfYtv+0v2s2rmq+qx9ZeFKNu7aiAu19vZs15Os9CyuGX4NWek+3Pt06KNwj1KNOcP/D+DLwJvOuTFmNhn4RmTLOj1PrHiCyRmTGdqteQa5SUuDMWN84P/oR82yS5GI23tkLysLV9YJ9017NlW/37t9b7J6ZfGNkd8gMz2TrPQs0tunB1ixnK7GBH6Zc263mSWYWYJz7m0zi5pe6PtK93H3m3dTcqyEGVkz+MmFP2mWmxhycuDhh+HAAegQl5evpSXbdXhX9cXUqmaZz/Z9Vv1+/479yUzP5MZzbiQzPZPM9Ex6tOsRYMUSDo0J/H1m1g54D3jOzIrw/fGjQqeUTmz8/kbuf/d+fpf7O55Z8wx3TbiLH47/IW2S2kRsv1OnwuzZ8Pbb8JWvRGw3ImestLyUlYUrWZK/hKUFS1mxYwWf76+5BPelzl8iu1c2M7JmkJWexZj0MXRr0y3AiiVSGhwt08weBV4AVgNH8HfZfgvoCDznnNsd7mLOdLTMjbs2cveiu3llwyv0at+L/5j8H9x4zo1N7p97MseOQZcuvmvmb38b9s2LNNnOkp0szV/KkvwlfJD/AbmFuRyrOAb4cB/beyyZPTPJ6pXFmJ5j6JzaOeCK5UyczmiZJwv824HrgHTgT8ALzrnVYauyHuEaHvm9be9x5xt3snz7ckamjeQXF/+CaYOmhf1C0j/9E6xbB1u2hHWzIo1WUVlBXlEeS/KXsKRgCUvyl/Dp3k8BaJ3Ymuxe2ZzX5zzO6+sfapaJPWEJ/Fob648P/uvw3TKfB/7knAv73E/hHA/fOce8dfO4e9HdfLr3U6YMmMJDlzzEmPQxYdk+wKOPwm23waZNMGhQ2DYr0qD9pftZvn25D/j8JSwrWMbBYwcB6NG2BxP6TagO+Mz0TJJbaRzvWBfWwD9uw2OAucAo51zY20kiMQHKsYpjPP7R49y/+H72HtnL9aOu54GLHqBfxzOfXWvTJj8hyqOPwq23hqFYkVqcc2zZu6U63JfkLyGvKA+HI8ESGNVjVJ2z94xOGeoOGYfCfYafBEzDn+FPAd7FN++8cqaFHi+SM17tK93Hg+89yK+X/xqA28fdzqyJs+iU0qnJ23QOBg6EkSPh1VfDVanEq9LyUnJ35Fa3vS/JX0Lx4WIAOiR3YHyf8dXhPrb3WDokq3uYhK8N/xJ8f/vLgQ+BF4FXnHOHwlXo8ZpjisPP93/OPW/dw7NrnqVLahfunXQvt5x7C60TWzdpe7fc4u+63b0bWjdtExKnCg8W1py9Fywhd0du9Tgzg7sMrg738/qex1ndz4rK0RcleOEK/Lfx7fUvO+f21LtSmDXnnLarCldx5xt3suizRQzsPJAHpzzIP5/1z6f9k/iVV+Dqq333zAsvjEyt0vKVV5ZXX1ytOnuvGj89OTGZc3ufW908M77v+GabEENavoi14Udac09i7pxjwZYF3PnGneQV5TGu9zgenvow5/c7v9HbOHAAunaFmTPhwQcjWKxEpdLyUnaW7KTwYCGFJYV1lgtLCquXiw4VVY81k94uvc7F1THpY5r8C1NEgX+aKiorePrjp7n37XvZcXAHVw27itlTZjd6qIZJk6CkBFaujHCh0iyccxw4eqA6sHeW7KwT3rWDfW/p3hM+n2AJpLVNI71dOunt0/3fdukM7z6cCX0n0K9jP11clbBR4DfRoWOHmLNsDrM/mM2RsiONHqrhpz+Fe+7xs2D1UDfnqFXpKik+VHxigNc+Ow89P1J+5ITPJycm1wR4rSDv2a5nnde7t+kekZv9ROqjwD9DRYeKuO+d+/hd7u9ITUo95VANK1bAuefCM8/A9dc3c7FSx+Gyw2zctZH1u9azvng963etZ+u+rRSWFPJFyRfV47PX1jG5Y53A7tm254nB3j6djskddWYuUUeBHyaNHaqhstKf2U+b5kNfIm/PkT3VgV79d9d6tu3bVj10b4IlMLDzQAZ2GVh9Nn58kPds15PUpNSA/zUiTafAD7P3P3+fmQtnnnSohm9+ExYtgsJCzYIVLs45Cg4UnBDqG3ZtoOhQUfV6Ka1SGNp1KMO7D2d4t9Cj+3AGdxmsO00l5inwI6BqqIZZi2axZe+WE4ZqePppmD4dli+HsWODrbWlKa8sZ8ueLfUGe8mxkur1Oqd0PiHUh3cbTv9O/dVHXeKWAj+CGhqqIfVYPwYPhnbt4LXXYNSooCuNPofLDrNh1wbWF/swrwr2Tbs31ZnYunf73vUGe1rbNLWhixxHgd8M9pXuY/b7s5mzbA7gh2r4p86zuO6qThw8CH/+M0yZ0rRtO+eocBVUVFZQ6SqbtOyco9JV4nA453CEnp9i+fjPNWa5oe0dOHqgOtTXF69n2/5t1f/GREtkYJeBJ4T6sG7DYnoSaZFwU+A3o9pDNXRM6UhaSm+2fV7J0bIK0npU0LbdqUO6woWeh5ZjSWqrVIZ2G3pCsA/qMkjt6yJhoMAPwKrCVcxZPoeSYyVUlCWwdEkiRTsTGT06gXPOTiTREkmwBBITTlxOTAg9b+JyfdtOsATMDMMwM//8FMuG1flcQ8uN3V7bpLb07dhX7esiEaTAjwJHj8J3vgPPPw833wy/+Q20asyEkiIip+F0Al8RFCHJyb5Pfr9+fu7b7dvhhRegbdugKxOReKXf2hGUkOAHVHv0UfjrX+Gii6Co6NSfExGJBAV+M7j1Vt9rZ80aOO882Lw56IpEJB4p8JvJVVfBW2/Bvn0wfry/QUtEpDkp8JvR+PGwZAl06ACTJ2taRBFpXgr8ZjZkCCxd6ufBvfpqeOKJoCsSkXihwA9AWpqfEvGyy/ycuD/6kZ8QXUQkkhT4AWnbFubPhxkzfE+eG26AY8eCrkpEYlnE++GbWSKwAtjunLsi0vtrSVq18k06/fvD//t/fmjll1+Gjh2DrkxEYlFznOHfDqxvhv20SGa+Sefpp+Hdd2HiRCgoCLoqEYlFEQ18M+sDXA78IZL7iQU33OCHVd661ffmycsLuiIRiTWRPsOfA/wbUNnQCmY2w8xWmNmK4uLiCJcT3S65BBYvhooKOP98f2FXRCRcIhb4ZnYFUOScyz3Zes65J51z2c657O7du0eqnBZj9GhYtgx694acHD/4mohIOETyDH8CcKWZbQVeBC4ys2cjuL+Y0a8fvP++b9r51rfgF79Qt00ROXMRC3zn3CznXB/nXAZwHfCWc+76SO0v1nTuDAsXwrXXwl13wW23+aYeEZGm0vDIUSw52Tfp9O0LDz/sh1h+/nlITQ26MhFpiZrlxivn3Dvqg980CQnw0EPw61/DX/7i58ndtSvoqkSkJdKdti3ED34A8+bBqlV+iOVPPw26IhFpaRT4Lcg118Cbb8Lu3f6C7kcfBV2RiLQkCvwWZsIE+OADaNMGLrwQ/va3oCsSkZZCgd8CDRvmh1geNgyuvBKefDLoikSkJVDgt1A9e/qxd6ZOhX/9V7j3XvXVF5GTU+C3YO3a+VmzvvtdeOABmD5dQyyLSMPUD7+FS0qC3//e35377//uh1ieN89PoygiUpvO8GOAGfz4xzB3rp8ofeJEeOMNNfGISF0K/Bjy7W/7XjtFRb5tf9Qo+OMfobQ06MpEJBoo8GNMTo4fU/+//gsSE+Gmm3xzz09+4g8EIhK/FPgxKDkZbrzR35W7aBGMGwf33eeD/6abNLmKSLxS4McwM7joIvjf/4UNG+A73/GDr519tv8l8PrraucXiScK/DgxdCj89reQnw8/+xl88glceimMGOF7+Rw5EnSFIhJpCvw407UrzJrl2/mfeQZSUmDGDN/c8+Mfw86dQVcoIpGiwI9TrVvD9ddDbi68844fgfOBB6B/f9/bZ82aoCsUkXBT4Mc5M7jgAj/W/saN8L3vwUsvwTnnwMUXw2uvQWWDU9CLSEuiwJdqgwfDo49CQQHMnu0v9F5+OZx1FjzxBBw+HHSFInImFPhygs6d/Ty6n30Gzz0H7dvDLbf4qRbvuccP3yAiLY8CXxqUlATf/CZ8+CG8955v+vnZz3w7/w03+H7+ItJyKPDllMzg/PPhz3+GTZv82f78+ZCZCZMn+37+aucXiX4KfDktAwf6CdXz8/3k6lu2+ElYhg3z/fwPHQq6QhFpiAJfmqRTJ5g50wf+iy/6dv9bb/Xt/LNmwfbtQVcoIsdT4MsZSUqCa6+FZcv8XLtTpsAvfgEZGf71Z5+F4uKgqxQR0AQoEiZm/uat887zvXseecT38HnpJf9eVpYfymHaNBg7FlrpvzyRZmcuikbPys7OditWrAi6DAmTykrfk+f11+Hvf/cTr1dW+uagSy7xB4CcHOjVK+hKRVouM8t1zmU3al0FvjSXvXv9cM1//7s/COzY4V8fNarm7P+88/ywDyLSOAp8iXrO+XHvMT0jAAAJrUlEQVT5q8L//fehrMzf5DVlig//adN8n38RaZgCX1qcgwf9fLxVzT/btvnXhw+vCf9Jk/zoniJSQ4EvLZpzfiC311/3j3fegaNHITXV3+g1bZpvAho0KOhKRYKnwJeYcvgwvPtuzdn/pk3+9YEDa87+J0+Gtm2DrVMkCAp8iWlbtsCCBT7833rLHxBat/ZNPlVn/8OH++6gIrFOgS9x4+hRf8G36uLv2rX+9b59a8J/8mTfFVQkFinwJW7l59e0/b/5Jhw44F8fNMjf/JWVBdnZfuC3jh2DrVUkHBT4IvhunkuX+iEfVqzw0zlW9f4BfxDIzq45EOggIC3R6QS+bnCXmJWU5Nv1J02qeW3XLh/8VY8lS/zgb1UGDz7xl0CHDs1fu0gk6Axf4l5xMaxcWfMrIDcXPv+85v3Bg0/8JaCDgESLqGjSMbMUYDGQjP8lMc859+8n+4wCX6JFcXHdXwIrVvjrA1WGDKn5FZCVBWPG6CAgwYiWwDegrXOuxMySgPeB251zyxr6jAJfollR0Ym/BKoOAmY1B4GqA8GYMX6oCJFIioo2fOePJCWhp0mhR/S0H4mcprS0mhu9qhQV1f0VsHgxPP+8f6/2QSA7G84+G4YOhd69IUEzUUgAItqGb2aJQC4wCHjMOXdXPevMAGYA9OvXL2tb7W4UIi3QF1+c2BxUewawNm38gWDIEH8AqHoMGaJmITl9UdGkU2cnZp2A+cBtzrm8htZTk47Eqi++gHXr/BhBGzfCP/7h/372Wd0J4Hv2rHsQqHpkZGjSGKlfVDTp1Oac22dm7wDTgAYDXyRW9ejhH5Mn13396FE/VETtg8DGjfDyy7B7d816SUl+7KD6DgZdu2oYCWmciAW+mXUHykJhnwpcDPw8UvsTaYmSk+Gss/zjeLt3n3gg2LjRDyNx7FjNep07n3gQGDLE31im4aSltkie4acDT4fa8ROAl5xzf43g/kRiSteuNfME11ZR4e8Yrn0Q2LgR3ngDnn66Zr2EBD+BzPEHgowMf+FYB4P4oxuvRGJIScmJvwiqnh86VHfd7t2hTx//6Nv3xOXevf0cBBLdoq4NX0SaR7t2/k7gzMy6rzvn5xD+xz/8XcQFBf4egoIC//yDD2DPnhO3163bqQ8Kbdo0z79NzpwCXyQOmPlw7t274XUOH/bdR6sOBLUPCvn5fiC62heSq3TpUv/BoPayDgrRQYEvIoAP5cGD/aMhR47UHAxqHxCqlpcv9wPUHa9z57oHgqpfB7161TzU2yjyFPgi0mipqY07KGzf3vBB4aOP/FhFx2vdGtLT6x4Ejj8o9Orlb07TgaFpFPgiElapqb5L6MkmmS8thZ07/XWF4x/bt/uZy954o2YCm9ratDnxIFDfQ3Mcn0iBLyLNLiXFdw/NyDj5eiUlUFhY/4Fhx46aYSuOHDnxsx061P8LofajZ8/46p6qwBeRqNWu3ambkJzzvwSqfh3Ud2BYvNj/LSs78fMpKf4aQ+fOfu7jxi536uRHQ21JzUsKfBFp0cz81JQdO8Lw4Q2vV1npu57WPhAUFsK+fbB3r3/s2+dfX7vWL+/f7w8oDUlM9MF/ugeKqr/NPT6SAl9E4kJCgr+voFs3GDWqcZ+prPS/HmofEE61/PnnNcv1/aKorV07H/4ZGf5XSKQp8EVEGpCQUHMGP2DA6X3WOX9toTEHi6SkyNR/PAW+iEgEmPkeRW3anPyGt+akeXdEROKEAl9EJE4o8EVE4oQCX0QkTijwRUTihAJfRCROKPBFROKEAl9EJE5E1Zy2ZlYMbGvix7sB9Uy9EJf0XdSl76MufR81YuG76O+c696YFaMq8M+Ema1o7ES+sU7fRV36PurS91Ej3r4LNemIiMQJBb6ISJyIpcB/MugCooi+i7r0fdSl76NGXH0XMdOGLyIiJxdLZ/giInISCnwRkTjR4gPfzKaZ2UYz22xmdwddT5DMrK+ZvW1m681srZndHnRNQTOzRDNbZWZ/DbqWoJlZJzObZ2YbQv+NjA+6piCZ2f8J/f8kz8xeMLOUoGuKtBYd+GaWCDwGXAqcBXzDzM4KtqpAlQP/1zk3HPgycGucfx8AtwPrgy4iSvwaeN05Nww4hzj+XsysN/ADINs5NxJIBK4LtqrIa9GBD4wFNjvnPnXOHQNeBL4ScE2Bcc4VOudWhpYP4v8PHSWTqzU/M+sDXA78IehagmZmHYBJwB8BnHPHnHP7gq0qcK2AVDNrBbQBdgRcT8S19MDvDeTXel5AHAdcbWaWAYwBlgdbSaDmAP8GVAZdSBT4ElAMPBVq4vqDmbUNuqigOOe2Aw8DnwOFwH7n3MJgq4q8lh74Vs9rcd/P1MzaAS8DdzjnDgRdTxDM7AqgyDmXG3QtUaIVkAk87pwbAxwC4vaal5l1xrcGDAB6AW3N7Ppgq4q8lh74BUDfWs/7EAc/y07GzJLwYf+cc+7PQdcToAnAlWa2Fd/Ud5GZPRtsSYEqAAqcc1W/+ObhDwDx6mLgM+dcsXOuDPgzcF7ANUVcSw/8j4DBZjbAzFrjL7q8GnBNgTEzw7fRrnfO/TLoeoLknJvlnOvjnMvA/3fxlnMu5s/gGuKc2wnkm9nQ0EtTgHUBlhS0z4Evm1mb0P9vphAHF7FbBV3AmXDOlZvZ94EF+Kvsc51zawMuK0gTgH8BPjGz1aHXfuScey3AmiR63AY8Fzo5+hT4dsD1BMY5t9zM5gEr8b3bVhEHwyxoaAURkTjR0pt0RESkkRT4IiJxQoEvIhInFPgiInFCgS8iEicU+BJXzKzCzFbXeoTtblMzyzCzvHBtTyTcWnQ/fJEmOOKcGx10ESJB0Bm+CGBmW83s52b2YegxKPR6fzNbZGZrQn/7hV7vYWbzzezj0KPqtvxEM/t9aJz1hWaWGtg/SuQ4CnyJN6nHNelcW+u9A865scCj+JE2CS3/t3NuFPAc8Ejo9UeAd51z5+DHpKm6w3sw8JhzbgSwD/hqhP89Io2mO20lrphZiXOuXT2vbwUucs59GhqAbqdzrquZ7QLSnXNlodcLnXPdzKwY6OOcO1prGxnAG865waHndwFJzrkHIv8vEzk1neGL1HANLDe0Tn2O1lquQNfJJIoo8EVqXFvr79LQ8hJqpr77FvB+aHkRcAtUz5vbobmKFGkqnX1IvEmtNZIo+Dleq7pmJpvZcvyJ0DdCr/0AmGtmd+JnjKoaYfJ24Ekz+y7+TP4W/MxJIlFLbfgiVLfhZzvndgVdi0ikqElHRCRO6AxfRCRO6AxfRCROKPBFROKEAl9EJE4o8EVE4oQCX0QkTvx/REKy/IH8jlIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(model, max_seq_len, label_one_hot, output_vocab, learning_rate, ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用模型进行实体识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_named_entity(input_vocab, sentence_input, pred, max_seq_len):\n",
    "    \"\"\"生成实体，要求 sentence_input 为输入的词的整数化的列表，一维， pre为预测的类别的列表，一维\"\"\"\n",
    "    named_entity = []\n",
    "    indices = []\n",
    "    for word_idx in range(max_seq_len):\n",
    "        if pred[word_idx] == 'C':\n",
    "            named_entity.append(input_vocab.to_tokens(sentence_input[word_idx]))\n",
    "        elif pred[word_idx] == 'B':\n",
    "            if pred[word_idx+1] != 'I' or pred[word_idx+1] != 'E':\n",
    "                named_entity.append(input_vocab.to_tokens(sentence_input[word_idx]))\n",
    "                indices.clear()\n",
    "            else:\n",
    "                indices.append(word_idx)\n",
    "        elif pred[word_idx] == 'I':\n",
    "            if pred[word_idx+1] != 'E' and pred[word_idx+1] != 'I':\n",
    "                concated_str = ''\n",
    "                for idx in indices:\n",
    "                    concated_str += input_vocab.to_tokens(sentence_input[idx])\n",
    "                named_entity.append(concated_str)\n",
    "                indices.clear()\n",
    "            else:\n",
    "                indices.append(word_idx)\n",
    "        elif pred[word_idx] == 'E':\n",
    "            indices.append(word_idx)\n",
    "            concated_str = ''\n",
    "            for idx in indices:\n",
    "                concated_str += input_vocab.to_tokens(sentence_input[idx])\n",
    "            named_entity.append(concated_str)\n",
    "            indices.clear()\n",
    "            \n",
    "    return named_entity            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_iter_test, test_batch_size, label_one_hot, output_vocab=output_vocab):\n",
    "    cate_num = label_one_hot.shape[0] -1 \n",
    "    \n",
    "    p = np.zeros((cate_num, ))\n",
    "    r = np.zeros((cate_num, ))\n",
    "    f1 = np.zeros((cate_num, ))\n",
    "    \n",
    "    batch_idx = 0\n",
    "    for test_x, test_y, nature in data_iter_test:\n",
    "        batch_preds = []\n",
    "        expand_batch_p = np.zeros((cate_num, ))\n",
    "        expand_batch_r = np.zeros((cate_num, ))\n",
    "        expand_batch_f1 = np.zeros((cate_num, ))\n",
    "        for word_idx in range(test_x.shape[1]): \n",
    "            distance = nd.arange(test_x.shape[1], ctx=ctx) - word_idx\n",
    "            distance = distance.reshape((1, -1))\n",
    "            # batch_distance 尺寸: (test_batch_size, max_seq_length)\n",
    "            batch_distance = nd.broadcast_axis(distance, axis=0, size=test_batch_size)                    \n",
    "                    \n",
    "            outputs = model(test_x, nature, batch_distance)\n",
    "            # preds 代表一个 batch 的第 word_idx 的词的输出，尺寸： (test_batch_size,)\n",
    "            preds = nd.argmax(nd.softmax(outputs, axis=1), axis=1)\n",
    "                    \n",
    "            # 扩展preds 为（test_batch_size, 1) 并添加入列表\n",
    "            batch_preds.append(nd.expand_dims(preds, axis=1)) \n",
    "            \n",
    "        batch_preds = nd.concat(*batch_preds, dim=1)\n",
    "        batch_p, batch_r, batch_f1 = cal_scores(batch_preds.asnumpy(), test_y.asnumpy())\n",
    "        expand_batch_p[0 : batch_p.shape[0]] = batch_p\n",
    "        expand_batch_r[0 : batch_r.shape[0]] = batch_r\n",
    "        expand_batch_f1[0 : batch_f1.shape[0]] = batch_f1\n",
    "        \n",
    "        batch_idx += 1\n",
    "        p += expand_batch_p\n",
    "        r += expand_batch_r\n",
    "        f1 += expand_batch_f1\n",
    "        \n",
    "    p /= batch_idx\n",
    "    r /= batch_idx\n",
    "    f1 /= batch_idx \n",
    "    print(\"TestData  : \", output_vocab.idx_to_token[1:])\n",
    "    print(\"Precision : \", p)\n",
    "    print(\"Recall    : \", r)\n",
    "    print(\"F1        : \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestData  :  ['N', 'C', 'B', 'E', 'I']\n",
      "Precision :  [0.97444295 0.93019735 0.85240456 0.84664384 0.82560736]\n",
      "Recall    :  [0.98635602 0.93072642 0.77595691 0.75128392 0.69676265]\n",
      "F1        :  [0.98036024 0.93033852 0.81212538 0.79583427 0.75415434]\n"
     ]
    }
   ],
   "source": [
    "test(model, data_iter_test, batch_size, label_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, sentences_input, nature, input_vocab, output_vocab):\n",
    "    batch_preds = [] \n",
    "    for word_idx in range(sentences_input.shape[1]): \n",
    "        distance = nd.arange(sentences_input.shape[1], ctx=ctx) - word_idx\n",
    "        distance = distance.reshape((1, -1))\n",
    "        batch_distance = nd.broadcast_axis(distance, axis=0, size=sentences_input.shape[0])\n",
    "        \n",
    "        outputs = model(sentences_input, nature, batch_distance)\n",
    "        preds = nd.argmax(nd.softmax(outputs, axis=1), axis=1)\n",
    "        \n",
    "        batch_preds.append(nd.expand_dims(preds, axis=1)) \n",
    "    batch_preds = nd.concat(*batch_preds, dim=1)\n",
    "    \n",
    "    named_entity_ls = []\n",
    "    for row in range(batch_preds.shape[0]):\n",
    "        pred_idx = [int(x) for x in list(batch_preds[row].asnumpy())]\n",
    "        sentence_word_idx = [int(x) for x in list(sentences_input[row].asnumpy())]\n",
    "        \n",
    "        pred_label = output_vocab.to_tokens(pred_idx)   \n",
    "        \n",
    "        named_entity = generate_named_entity(input_vocab, sentence_word_idx, pred_label, max_seq_len)\n",
    "        named_entity_ls.append(named_entity)\n",
    "    return named_entity_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "真实的句子： ['10', '合肥市', '第二', '人民', '医院', '15655', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "预测的实体:  ['合肥市', '人民医院']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences_input = nd.array(X_test[10:11], ctx=ctx)\n",
    "sub_nature = nd.array(nature[10:11], ctx=ctx)\n",
    "\n",
    "named_entity_pred = predict(model, sentences_input, sub_nature, input_vocab, output_vocab)\n",
    "\n",
    "for example_idx in range(sentences_input.shape[0]):\n",
    "    sentece = input_vocab.to_tokens([int(x) for x in sentences_input[example_idx].asnumpy()])\n",
    "    print(\"真实的句子：\", sentece)\n",
    "    print(\"预测的实体: \", named_entity_pred[example_idx])\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'C', 'B', 'E', 'I']\n"
     ]
    }
   ],
   "source": [
    "print(output_vocab.idx_to_token[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
