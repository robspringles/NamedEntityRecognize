{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 CNN 进行命名实体识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入相关模块并设置一些参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import collections\n",
    "import time\n",
    "import os\n",
    "\n",
    "from mxnet import autograd, gluon, nd\n",
    "from mxnet.gluon import nn, rnn, Block\n",
    "from mxnet.contrib import text\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from io import open\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = '<PAD>'\n",
    "NOT = 'N'\n",
    "PAD_NATURE = 'r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "drop_prob = 0.2\n",
    "batch_size = 256\n",
    "learning_rate = 0.01\n",
    "\n",
    "max_seq_len = 30\n",
    "\n",
    "word_vec_size = 200\n",
    "nature_vec_size = 50\n",
    "distance_vec_size = 50\n",
    "num_channels = 10\n",
    "conv_width = word_vec_size + nature_vec_size + distance_vec_size\n",
    "kernels_size_ls = [(2, conv_width), (3, conv_width), (4, conv_width)]\n",
    "padding_ls = None\n",
    "pool_size = (2, 1) \n",
    "output_size = 6\n",
    "distance_size = 2 * max_seq_len - 1\n",
    "\n",
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义一些辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(max_seq_len):\n",
    "    \"\"\"读取数据\"\"\"\n",
    "    input_tokens = []   # 记录输入 X 的所有词，包含重复\n",
    "    output_tokens = []  # 记录输出 Y 的所有符号，包含重复\n",
    "    nature_tokens = []  # 记录所有词的词性的符号，包含重复\n",
    "    input_seqs = []  # 列表中装的列表，里面的每个列表代表一条输入，填充或截断好了的\n",
    "    output_seqs = []  # 同input_seqs\n",
    "    nature_seqs = []\n",
    "    \n",
    "    with open(\"../data_for_seq2seq/re_cut_lines_word.txt\", 'r') as fx, open(\"../data_for_seq2seq/re_cut_lines_label.txt\", 'r') as fy, open(\"../data_for_seq2seq/re_cut_lines_nature.txt\", 'r') as fn:\n",
    "        word_lines = fx.readlines()\n",
    "        label_lines = fy.readlines()\n",
    "        word_natures = fn.readlines()\n",
    "        \n",
    "        for word_line, lable_line, word_nature in zip(word_lines, label_lines, word_natures):\n",
    "            \n",
    "            input_seq = word_line.strip()\n",
    "            output_seq = lable_line.strip()\n",
    "            nature_seq = word_nature.strip()\n",
    "            \n",
    "            cur_input_tokens = input_seq.split(' ')\n",
    "            cur_output_tokens = output_seq.split(' ')\n",
    "            cur_nature_tokens = nature_seq.split(' ')\n",
    "            \n",
    "            if '' in cur_output_tokens:\n",
    "                continue\n",
    "            \n",
    "            if len(cur_input_tokens) < max_seq_len or len(cur_output_tokens) < max_seq_len or len(cur_nature_tokens) < max_seq_len:\n",
    "                input_tokens.extend(cur_input_tokens)\n",
    "                output_tokens.extend(cur_output_tokens)\n",
    "                nature_tokens.extend(cur_nature_tokens)\n",
    "                \n",
    "                # 添加 PAD 符号使每个序列等长，长度为 max_seq_len\n",
    "                while len(cur_input_tokens) < max_seq_len:\n",
    "                    cur_input_tokens.append(PAD)\n",
    "                    # 把输出也填充到了最大长度\n",
    "                    cur_output_tokens.append(NOT)\n",
    "                    cur_nature_tokens.append(PAD_NATURE)\n",
    "                    \n",
    "                input_seqs.append(cur_input_tokens)                            \n",
    "                output_seqs.append(cur_output_tokens)\n",
    "                nature_seqs.append(cur_nature_tokens)\n",
    "                \n",
    "            else:\n",
    "                cur_input_tokens = cur_input_tokens[0: max_seq_len]\n",
    "                cur_output_tokens = cur_output_tokens[0: max_seq_len]\n",
    "                cur_nature_tokens = cur_nature_tokens[0: max_seq_len]\n",
    "                \n",
    "                input_tokens.extend(cur_input_tokens)\n",
    "                input_seqs.append(cur_input_tokens)\n",
    "                \n",
    "                output_tokens.extend(cur_output_tokens)\n",
    "                output_seqs.append(cur_output_tokens)\n",
    "                \n",
    "                nature_tokens.extend(cur_nature_tokens)\n",
    "                nature_seqs.append(cur_nature_tokens)\n",
    "                \n",
    "        fr_vocab = text.vocab.Vocabulary(collections.Counter(input_tokens), reserved_tokens=[PAD])\n",
    "        print(collections.Counter(output_tokens))\n",
    "        en_vocab = text.vocab.Vocabulary(collections.Counter(output_tokens))\n",
    "        \n",
    "        nature_vocab = text.vocab.Vocabulary(collections.Counter(nature_tokens))\n",
    "    \n",
    "    return fr_vocab, en_vocab, nature_vocab, input_seqs, output_seqs, nature_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cnn_input(word_data, nature, batch_distance, pos):\n",
    "    \"\"\"生成满足模型的输入\"\"\"\n",
    "    x_input = word_data[:, pos]\n",
    "    nature_input = nature[:, pos]\n",
    "    distance_input = batch_distance[:, pos]\n",
    "    \n",
    "    return x_input, nature_input, distance_input   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_scores(y_hat, label):\n",
    "    \"\"\"计算结果的评分指标\"\"\"\n",
    "    # 将预测结果与真实标记都变为一维数组以方便计算\n",
    "    y_hat = y_hat.reshape((-1, ))\n",
    "    label = label.reshape((-1, ))\n",
    "    # average 置为 None，可以返回每个类别的 P R F\n",
    "    p = metrics.precision_score(label, y_hat, average='micro')\n",
    "    r = metrics.recall_score(label, y_hat, average='micro')\n",
    "    f1 = metrics.f1_score(label, y_hat, average='micro')\n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据的预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'N': 7739104, 'C': 626209, 'B': 566764, 'E': 544024, 'I': 153734})\n"
     ]
    }
   ],
   "source": [
    "input_vocab, output_vocab, nature_vocab, input_seqs, output_seqs, nature_seqs = read_data(max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215540"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', 'N', 'C', 'B', 'E', 'I']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_vocab.idx_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nature_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"../data_for_cnn_lstm/X.npy\") and  os.path.exists(\"../data_for_cnn_lstm/Y.npy\") and os.path.exists(\"../data_for_cnn_lstm/nature.npy\"):\n",
    "    print(\"Loading...\")\n",
    "    X = np.load(\"../data_for_cnn_lstm/X.npy\")\n",
    "    Y = np.load(\"../data_for_cnn_lstm/Y.npy\")\n",
    "    nature = np.load(\"../data_for_cnn_lstm/nature.npy\")\n",
    "    print(\"End\")\n",
    "else:\n",
    "    print(\"Converting...\")\n",
    "    X = nd.zeros((len(input_seqs), max_seq_len))\n",
    "    Y = nd.zeros((len(output_seqs), max_seq_len))\n",
    "    nature = nd.zeros((len(nature_seqs), max_seq_len))\n",
    "    \n",
    "    for i in range(len(input_seqs)):\n",
    "        X[i] = nd.array(input_vocab.to_indices(input_seqs[i]))\n",
    "        Y[i] = nd.array(output_vocab.to_indices(output_seqs[i]))\n",
    "        nature[i] = nd.array(nature_vocab.to_indices(nature_seqs[i]))\n",
    "    np.save(\"../data_for_cnn_lstm/X.npy\", X.asnumpy())\n",
    "    np.save(\"../data_for_cnn_lstm/Y.npy\", Y.asnumpy())\n",
    "    np.save(\"../data_for_cnn_lstm/nature.npy\", nature.asnumpy())\n",
    "    print(\"End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((429469, 30), (429469, 30))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nature.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((420879, 30), (420879, 30), (420879, 30)),\n",
       " ((8590, 30), (8590, 30), (8590, 30)))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test, nature_train, nature_test = train_test_split(X, Y, nature, test_size=0.02, random_state=33)\n",
    "((X_train.shape, Y_train.shape, nature_train.shape), (X_test.shape, Y_test.shape, nature_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = gluon.data.ArrayDataset(nd.array(X_train, ctx=ctx), nd.array(Y_train, ctx=ctx), nd.array(nature_train, ctx=ctx))\n",
    "data_iter_train = gluon.data.DataLoader(dataset_train, batch_size, shuffle=True, last_batch='rollover')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, Y_train, nature_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(nn.Block):\n",
    "    def __init__(self, vocab_size, word_vec_size, nature_size, nature_vec_size, distance_size, distance_vec_size,\n",
    "                 num_channels, kernels_size_ls, padding_ls, pool_size, output_size,\n",
    "                 drop_prob=0.2,  **kwargs):\n",
    "        super(CNN_Model, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.word_embedding = nn.Embedding(vocab_size, word_vec_size)\n",
    "            self.nature_embedding = nn.Embedding(nature_size, nature_vec_size)\n",
    "            self.distance_embedding = nn.Embedding(distance_size, distance_vec_size)\n",
    "            self.num_channels = num_channels\n",
    "            self.kernels_size_ls = kernels_size_ls\n",
    "            self.conv_ls = []\n",
    "            for kernel_size in kernels_size_ls:\n",
    "                conv = nn.Conv2D(channels=num_channels, kernel_size=kernel_size, activation='relu')\n",
    "                self.register_child(conv)\n",
    "                self.conv_ls.append(conv)\n",
    "            self.max_pool = nn.MaxPool2D(pool_size=pool_size)\n",
    "            self.flatten = nn.Flatten()\n",
    "            self.dense = nn.Dense(output_size)\n",
    "            self.drop = nn.Dropout(drop_prob)\n",
    "        \n",
    "    def forward(self, x_input, nature_input, distance_input):\n",
    "        batch_words_embed = self.word_embedding(x_input)\n",
    "        batch_nature_embed = self.nature_embedding(nature_input)\n",
    "        batch_distance_embed = self.distance_embedding(distance_input)\n",
    "        \n",
    "        # (batch_size, height, width)\n",
    "        batch_data_x = nd.concat(batch_words_embed, batch_nature_embed, batch_distance_embed, dim=2)\n",
    "        # (batch_size, 1, height, width)\n",
    "        batch_data_x = nd.expand_dims(batch_data_x, axis=1)\n",
    "        \n",
    "        conv_pool_result = []\n",
    "        for conv in self.conv_ls:\n",
    "            conv_result = conv(batch_data_x)    # (batch_size, num_channels, out_height, out_width)\n",
    "            pool_result = self.max_pool(conv_result)    # (batch_size, num_channels, new_height, new_width)\n",
    "            pool_result = self.flatten(pool_result)\n",
    "            conv_pool_result.append(pool_result)\n",
    "        # (batch_size, len(kernel_size_ls)*num_channels*new_height,new_width)\n",
    "        conv_pool_result_concated = nd.concat(*conv_pool_result, dim=1)\n",
    "        conv_pool_result_concated = self.drop(conv_pool_result_concated)\n",
    "        output = self.dense(conv_pool_result_concated)\n",
    "        \n",
    "        return output   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建一个输出标签的one-hot矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[1. 0. 0. 0. 0. 0.]\n",
       " [0. 1. 0. 0. 0. 0.]\n",
       " [0. 0. 1. 0. 0. 0.]\n",
       " [0. 0. 0. 1. 0. 0.]\n",
       " [0. 0. 0. 0. 1. 0.]\n",
       " [0. 0. 0. 0. 0. 1.]]\n",
       "<NDArray 6x6 @gpu(0)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_value = nd.array(list(output_vocab.token_to_idx.values()), ctx=ctx)\n",
    "\n",
    "label_one_hot = nd.one_hot(dic_value, dic_value.shape[0])\n",
    "\n",
    "label_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义训练函数，并实例化模型，开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, max_seq_len, label_one_hot, output_vocab, learning_rate, ctx):\n",
    "    \"\"\"训练函数\"\"\"\n",
    "    model.collect_params().initialize(mx.init.Xavier(), ctx=ctx)\n",
    "    \n",
    "    optimizer = gluon.Trainer(model.collect_params(), 'adam',\n",
    "                                      {'learning_rate': learning_rate})\n",
    "\n",
    "    softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss(sparse_label=False)\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    total_loss = []   \n",
    "    for epoch in range(0, epochs):\n",
    "        p = 0.0\n",
    "        r = 0.0\n",
    "        f1 = 0.0      \n",
    "        epoch_loss = 0.0\n",
    "        batch_idx = 0\n",
    "        for x, y, nature in data_iter_train:\n",
    "            batch_preds = []\n",
    "            with autograd.record():\n",
    "                batch_loss = nd.array([0], ctx=ctx)              \n",
    "                for word_idx in range(x.shape[1]): \n",
    "                    distance = nd.arange(x.shape[1], ctx=ctx) - word_idx\n",
    "                    distance = distance.reshape((1, -1))\n",
    "                    # batch_distance 尺寸: (batch_size, max_seq_length)\n",
    "                    batch_distance = nd.broadcast_axis(distance, axis=0, size=batch_size)                    \n",
    "                    \n",
    "                    outputs = model(x, nature, batch_distance)\n",
    "                    # preds 代表一个 batch 的第 word_idx 的词的输出，尺寸： (batch_size,)\n",
    "                    preds = nd.argmax(nd.softmax(outputs, axis=1), axis=1)\n",
    "                    \n",
    "                    # 扩展preds 为（batch_size, 1) 并添加入列表\n",
    "                    batch_preds.append(nd.expand_dims(preds, axis=1))              \n",
    "                    y_idx = y[:, word_idx]\n",
    "                    label = nd.take(label_one_hot, y_idx)\n",
    "                    \n",
    "                    batch_loss = batch_loss + nd.mean(softmax_cross_entropy(outputs, label))\n",
    "                \n",
    "            batch_loss.backward()\n",
    "            optimizer.step(batch_size)\n",
    "            \n",
    "            # 将一批的每个词的输出组合,得到一批的模型的输出\n",
    "            # 尺寸为 : (batch_size, max_seq_len)\n",
    "            batch_preds = nd.concat(*batch_preds, dim=1)\n",
    "            epoch_loss += batch_loss.asscalar()                     \n",
    "            \n",
    "            if batch_idx % 500 == 0:\n",
    "                print(\"epoch: {0} , batch: {1}, batch_loss: {2}\".format(epoch, batch_idx, batch_loss.asscalar()))\n",
    "                for example in range(2):\n",
    "                    true_idx = [int(x) for x in list(y[example].asnumpy())]\n",
    "                    pred_idx = [int(x) for x in list(batch_preds[example].asnumpy())]\n",
    "                    \n",
    "                    true_label = output_vocab.to_tokens(true_idx)\n",
    "                    pred_label = output_vocab.to_tokens(pred_idx)\n",
    "                    \n",
    "                    print(\"Sapmle {0} :\".format(example))\n",
    "                    print(\"True label : {0}\".format(true_label))\n",
    "                    print(\"Pred label : {0}\".format(pred_label))\n",
    "            \n",
    "            batch_p, batch_r, batch_f1 = cal_scores(batch_preds.asnumpy(), y.asnumpy())\n",
    "            p += batch_p\n",
    "            r += batch_r\n",
    "            f1 += batch_f1           \n",
    "            batch_idx += 1          \n",
    "        \n",
    "        epoch_loss = epoch_loss / batch_idx\n",
    "        p /= batch_idx\n",
    "        r /= batch_idx\n",
    "        f1 /= batch_idx\n",
    "        total_loss.append(epoch_loss)\n",
    "        \n",
    "        print(\"epoch: {0} , epoch_loss: {1}\".format(epoch, epoch_loss))\n",
    "        print(\"TrainData:  P: {0}, R: {1}, F: {2}\".format(p, r, f1))\n",
    "        print(\"-----------------------------------------------------\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(\"训练结束，用时 {0} 秒\".format(str(end_time-start_time)))\n",
    "    # 绘制每个 epoch 的loss的变化曲线图\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.plot(range(epochs), total_loss)\n",
    "    plt.show()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_Model(len(input_vocab), word_vec_size, len(nature_vocab), nature_vec_size, distance_size, distance_vec_size,\n",
    "                 num_channels, kernels_size_ls, padding_ls, pool_size, output_size, drop_prob=drop_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\developtool\\python\\lib\\site-packages\\mxnet\\gluon\\block.py:228: UserWarning: \"CNN_Model.conv_ls\" is a container with Blocks. Note that Blocks inside the list, tuple or dict will not be registered automatically. Make sure to register them using register_child() or switching to nn.Sequential/nn.HybridSequential instead. \n",
      "  .format(name=self.__class__.__name__ + \".\" + k))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 , batch: 0, batch_loss: 54.45577621459961\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'B', 'E', 'N', 'C', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'I', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'I', 'I', '<unk>', '<unk>', '<unk>', 'I', '<unk>', 'I', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'B', '<unk>', 'B', 'B', '<unk>', '<unk>', '<unk>', '<unk>', 'B', '<unk>', '<unk>', '<unk>']\n",
      "Sapmle 1 :\n",
      "True label : ['C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['<unk>', '<unk>', 'I', 'I', 'I', 'I', 'I', '<unk>', 'B', 'I', '<unk>', 'I', '<unk>', 'I', 'B', 'B', 'I', 'C', 'B', 'B', 'B', 'I', '<unk>', 'B', 'B', 'B', 'B', '<unk>', 'B', 'B']\n",
      "epoch: 0 , batch: 500, batch_loss: 6.4006218910217285\n",
      "Sapmle 0 :\n",
      "True label : ['B', 'E', 'C', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['B', 'E', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['C', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'B', 'E', 'B', 'E']\n",
      "Pred label : ['C', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N']\n",
      "epoch: 0 , batch: 1000, batch_loss: 5.7624053955078125\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 0 , batch: 1500, batch_loss: 4.787276268005371\n",
      "Sapmle 0 :\n",
      "True label : ['B', 'E', 'N', 'N', 'N', 'N', 'N', 'B', 'I', 'E', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'E', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 0 , epoch_loss: 6.954202611661016\n",
      "TrainData:  P: 0.92542761240369, R: 0.92542761240369, F: 0.92542761240369\n",
      "-----------------------------------------------------\n",
      "epoch: 1 , batch: 0, batch_loss: 4.249391078948975\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'B', 'N', 'N', 'N', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N']\n",
      "epoch: 1 , batch: 500, batch_loss: 4.458939552307129\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'C', 'N', 'C', 'N', 'N', 'C', 'N', 'B', 'E', 'N', 'N', 'C', 'C', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'C', 'N', 'C', 'N', 'N', 'C', 'N', 'B', 'E', 'N', 'N', 'C', 'C', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['B', 'E', 'B', 'E', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['B', 'C', 'C', 'E', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 1 , batch: 1000, batch_loss: 4.634707450866699\n",
      "Sapmle 0 :\n",
      "True label : ['B', 'E', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['C', 'E', 'B', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['C', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['C', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 1 , batch: 1500, batch_loss: 4.205491542816162\n",
      "Sapmle 0 :\n",
      "True label : ['E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'I', 'E', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'E', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'I', 'E', 'E', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 1 , epoch_loss: 4.383662125925078\n",
      "TrainData:  P: 0.950551088554339, R: 0.950551088554339, F: 0.950551088554339\n",
      "-----------------------------------------------------\n",
      "epoch: 2 , batch: 0, batch_loss: 3.512199878692627\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'B', 'E', 'B', 'E', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'I', 'E', 'B', 'E', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 2 , batch: 500, batch_loss: 3.294231414794922\n",
      "Sapmle 0 :\n",
      "True label : ['B', 'E', 'C', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'B', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['B', 'E', 'C', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'B', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 2 , batch: 1000, batch_loss: 3.6411795616149902\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 , batch: 1500, batch_loss: 4.0240302085876465\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 2 , epoch_loss: 3.7597160667108502\n",
      "TrainData:  P: 0.9569973514801293, R: 0.9569973514801293, F: 0.9569973514801293\n",
      "-----------------------------------------------------\n",
      "epoch: 3 , batch: 0, batch_loss: 3.4164505004882812\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'C', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'B', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'C', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'E', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 3 , batch: 500, batch_loss: 3.188310384750366\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 3 , batch: 1000, batch_loss: 3.0859830379486084\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['B', 'E', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'C', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['B', 'E', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 3 , batch: 1500, batch_loss: 4.260101318359375\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 3 , epoch_loss: 3.423825000179365\n",
      "TrainData:  P: 0.9605787934661392, R: 0.9605787934661392, F: 0.9605787934661392\n",
      "-----------------------------------------------------\n",
      "epoch: 4 , batch: 0, batch_loss: 3.052973985671997\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'C', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'C', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 4 , batch: 500, batch_loss: 2.830498695373535\n",
      "Sapmle 0 :\n",
      "True label : ['C', 'N', 'N', 'C', 'C', 'C', 'N', 'B', 'E', 'C', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'C', 'N', 'C', 'N', 'N', 'N', 'N', 'C', 'C', 'N', 'N', 'N']\n",
      "Pred label : ['C', 'N', 'N', 'C', 'C', 'C', 'N', 'B', 'E', 'C', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'C', 'N', 'C', 'N', 'N', 'N', 'N', 'C', 'C', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'B', 'I', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'B', 'I', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'E', 'N', 'N', 'N', 'N']\n",
      "epoch: 4 , batch: 1000, batch_loss: 2.885089159011841\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'B', 'E', 'C', 'N', 'N', 'C', 'N', 'N', 'C', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'E', 'C', 'N', 'N', 'C', 'N', 'N', 'C', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'E', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 4 , batch: 1500, batch_loss: 3.7821197509765625\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['B', 'E', 'N', 'C', 'N', 'C', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'E', 'C', 'N', 'C', 'N', 'N', 'N', 'B', 'I', 'E', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['B', 'E', 'N', 'C', 'N', 'C', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'E', 'C', 'N', 'C', 'N', 'N', 'N', 'B', 'E', 'E', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 4 , epoch_loss: 3.220473169700363\n",
      "TrainData:  P: 0.962679788878751, R: 0.962679788878751, F: 0.962679788878751\n",
      "-----------------------------------------------------\n",
      "epoch: 5 , batch: 0, batch_loss: 3.535553455352783\n",
      "Sapmle 0 :\n",
      "True label : ['C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'C', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'C', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 5 , batch: 500, batch_loss: 3.726027727127075\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'C', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'C', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 , batch: 1000, batch_loss: 3.279947519302368\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'C', 'C', 'B', 'E', 'N', 'B', 'E', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'C', 'C', 'B', 'E', 'B', 'B', 'E', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'C', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'C', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 5 , batch: 1500, batch_loss: 2.8479771614074707\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 5 , epoch_loss: 3.081573119563778\n",
      "TrainData:  P: 0.9641780559357261, R: 0.9641780559357261, F: 0.9641780559357261\n",
      "-----------------------------------------------------\n",
      "epoch: 6 , batch: 0, batch_loss: 3.035921335220337\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 6 , batch: 500, batch_loss: 3.666349172592163\n",
      "Sapmle 0 :\n",
      "True label : ['B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['E', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 6 , batch: 1000, batch_loss: 3.16123628616333\n",
      "Sapmle 0 :\n",
      "True label : ['B', 'E', 'C', 'N', 'C', 'N', 'B', 'I', 'E', 'N', 'C', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'B', 'E', 'N', 'N', 'N', 'C', 'N', 'B', 'E']\n",
      "Pred label : ['B', 'E', 'C', 'N', 'C', 'N', 'B', 'I', 'E', 'N', 'C', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'B', 'E', 'N', 'N', 'N', 'C', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'C']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'E', 'N', 'N', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 6 , batch: 1500, batch_loss: 3.394221544265747\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 6 , epoch_loss: 2.9694222062463598\n",
      "TrainData:  P: 0.9653447035938773, R: 0.9653447035938773, F: 0.9653447035938773\n",
      "-----------------------------------------------------\n",
      "epoch: 7 , batch: 0, batch_loss: 3.154597759246826\n",
      "Sapmle 0 :\n",
      "True label : ['C', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['C', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 7 , batch: 500, batch_loss: 2.8415262699127197\n",
      "Sapmle 0 :\n",
      "True label : ['C', 'B', 'I', 'E', 'N', 'N', 'C', 'N', 'N', 'N', 'B', 'I', 'E', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'C', 'C', 'N', 'N', 'N', 'C', 'N', 'N', 'B', 'E']\n",
      "Pred label : ['C', 'B', 'I', 'E', 'N', 'N', 'C', 'N', 'N', 'N', 'B', 'I', 'E', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'C', 'C', 'N', 'N', 'N', 'C', 'N', 'N', 'C', 'E']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'I', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 7 , batch: 1000, batch_loss: 2.8758633136749268\n",
      "Sapmle 0 :\n",
      "True label : ['C', 'B', 'I', 'I', 'E', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'B', 'E', 'N']\n",
      "Pred label : ['C', 'B', 'I', 'I', 'E', 'N', 'N', 'C', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'B', 'E', 'E']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N']\n",
      "Pred label : ['N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N']\n",
      "epoch: 7 , batch: 1500, batch_loss: 3.0440194606781006\n",
      "Sapmle 0 :\n",
      "True label : ['C', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['C', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['C', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N']\n",
      "Pred label : ['C', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N']\n",
      "epoch: 7 , epoch_loss: 2.885960833724688\n",
      "TrainData:  P: 0.9661721284468764, R: 0.9661721284468764, F: 0.9661721284468764\n",
      "-----------------------------------------------------\n",
      "epoch: 8 , batch: 0, batch_loss: 2.4980900287628174\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'C', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'B', 'E', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'E', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'E', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['B', 'E', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['B', 'E', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 , batch: 500, batch_loss: 2.5189945697784424\n",
      "Sapmle 0 :\n",
      "True label : ['B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['B', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['B', 'E', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['B', 'E', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 8 , batch: 1000, batch_loss: 3.593825340270996\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'B', 'I', 'I', 'E', 'N', 'C', 'C', 'N', 'N', 'N', 'N', 'B', 'I', 'E', 'N', 'B', 'E', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'B', 'I', 'I', 'E', 'N', 'C', 'C', 'N', 'N', 'N', 'N', 'B', 'I', 'E', 'N', 'B', 'E', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 8 , batch: 1500, batch_loss: 2.3856003284454346\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'B', 'E', 'C', 'N', 'N', 'N', 'N', 'C', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'E', 'N', 'N', 'N', 'N', 'N', 'C', 'B', 'E', 'C', 'N', 'N', 'N', 'N', 'C', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['C', 'C', 'B', 'E', 'N', 'N', 'C', 'C', 'C', 'N', 'C', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'B', 'E', 'N', 'C', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['C', 'C', 'B', 'E', 'N', 'N', 'C', 'C', 'C', 'N', 'C', 'B', 'I', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'B', 'E', 'N', 'C', 'N', 'N', 'N', 'E']\n",
      "epoch: 8 , epoch_loss: 2.827243930884521\n",
      "TrainData:  P: 0.9668481979927008, R: 0.9668481979927008, F: 0.9668481979927008\n",
      "-----------------------------------------------------\n",
      "epoch: 9 , batch: 0, batch_loss: 2.396205186843872\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'C', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'C', 'N', 'N', 'N', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 9 , batch: 500, batch_loss: 2.8519351482391357\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'B', 'I', 'E', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'B', 'I', 'E', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'C', 'N', 'C', 'N', 'B', 'E', 'C', 'N', 'C', 'N', 'N', 'N', 'N', 'C', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N']\n",
      "Pred label : ['N', 'C', 'N', 'C', 'N', 'B', 'E', 'C', 'N', 'C', 'N', 'N', 'N', 'N', 'C', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N']\n",
      "epoch: 9 , batch: 1000, batch_loss: 3.0280985832214355\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'B', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 9 , batch: 1500, batch_loss: 2.687319040298462\n",
      "Sapmle 0 :\n",
      "True label : ['C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'C', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'C', 'N', 'N', 'N']\n",
      "Pred label : ['C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'C', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'C', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'B']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'E', 'C', 'N']\n",
      "epoch: 9 , epoch_loss: 2.7699523495641647\n",
      "TrainData:  P: 0.967465657948095, R: 0.967465657948095, F: 0.967465657948095\n",
      "-----------------------------------------------------\n",
      "训练结束，用时 6903.729874610901 秒\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(model, max_seq_len, label_one_hot, output_vocab, learning_rate, ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义测试函数，并在测试集上测试训练好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_iter_test, test_batch_size, label_one_hot, output_vocab=output_vocab):\n",
    "    p = 0.0\n",
    "    r = 0.0\n",
    "    f1 = 0.0\n",
    "    \n",
    "    batch_idx = 0\n",
    "    for test_x, test_y, nature in data_iter_test:\n",
    "        batch_preds = []\n",
    "        for word_idx in range(test_x.shape[1]): \n",
    "            distance = nd.arange(test_x.shape[1], ctx=ctx) - word_idx\n",
    "            distance = distance.reshape((1, -1))\n",
    "            # batch_distance 尺寸: (test_batch_size, max_seq_length)\n",
    "            batch_distance = nd.broadcast_axis(distance, axis=0, size=test_batch_size)                    \n",
    "                    \n",
    "            outputs = model(test_x, nature, batch_distance)\n",
    "            # preds 代表一个 batch 的第 word_idx 的词的输出，尺寸： (test_batch_size,)\n",
    "            preds = nd.argmax(nd.softmax(outputs, axis=1), axis=1)\n",
    "                    \n",
    "            # 扩展preds 为（test_batch_size, 1) 并添加入列表\n",
    "            batch_preds.append(nd.expand_dims(preds, axis=1)) \n",
    "            \n",
    "        batch_preds = nd.concat(*batch_preds, dim=1)\n",
    "        batch_p, batch_r, batch_f1 = cal_scores(batch_preds.asnumpy(), test_y.asnumpy())\n",
    "#         print(\"batch_test_label: \", output_vocab.idx_to_token)      \n",
    "#         print(\"batch_Precision : \", batch_p)\n",
    "#         print(\"batch_Recall    : \", batch_r)\n",
    "#         print(\"batch_F1        : \", batch_f1)\n",
    "        batch_idx += 1\n",
    "        p += batch_p\n",
    "        r += batch_r\n",
    "        f1 += batch_f1\n",
    "        \n",
    "    p /= batch_idx\n",
    "    r /= batch_idx\n",
    "    f1 /= batch_idx     \n",
    "    print(\"Precision : \", p)\n",
    "    print(\"Recall    : \", r)\n",
    "    print(\"F1        : \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = batch_size\n",
    "dataset_test = gluon.data.ArrayDataset(nd.array(X_test, ctx=ctx), nd.array(Y_test, ctx=ctx), nd.array(nature_test, ctx=ctx))\n",
    "data_iter_test = gluon.data.DataLoader(dataset_test, batch_size, shuffle=True, last_batch='discard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision :  0.9603061868686869\n",
      "Recall    :  0.9603061868686869\n",
      "F1        :  0.9603061868686869\n"
     ]
    }
   ],
   "source": [
    "test(model, data_iter_test, test_batch_size, label_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
