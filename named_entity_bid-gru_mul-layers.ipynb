{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import os\n",
    "\n",
    "from mxnet import autograd, gluon, nd\n",
    "from mxnet.gluon import nn, rnn, Block\n",
    "from mxnet.contrib import text\n",
    "from sklearn import metrics\n",
    "\n",
    "from io import open\n",
    "import collections\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = '<PAD>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "hidden_dim = 400\n",
    "drop_prob = 0.2\n",
    "batch_size = 256\n",
    "learning_rate = 0.01\n",
    "num_layers = 2\n",
    "dense_hidden_dim = 300\n",
    "bidirectional = True\n",
    "\n",
    "max_seq_len = 30\n",
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(max_seq_len):\n",
    "    input_tokens = []   # 记录编码器输入 X 的所有词，包含重复\n",
    "    output_tokens = []  # 记录解码器输出 Y 的所有符号，包含重复\n",
    "    input_seqs = []  # 列表中装的列表，里面的每个列表代表一条输入，填充或截断好了的\n",
    "    output_seqs = []  # 同input_seqs\n",
    "    \n",
    "    with open(\"../data_for_seq2seq/re_cut_lines_word.txt\", 'r') as fx, open(\"../data_for_seq2seq/re_cut_lines_label.txt\", 'r') as fy:\n",
    "        word_lines = fx.readlines()\n",
    "        label_lines = fy.readlines()\n",
    "        \n",
    "        for word_line, lable_line in zip(word_lines, label_lines):\n",
    "            \n",
    "            input_seq = word_line.strip()\n",
    "            output_seq = lable_line.strip()\n",
    "            \n",
    "            cur_input_tokens = input_seq.split(' ')\n",
    "            cur_output_tokens = output_seq.split(' ')\n",
    "            \n",
    "            if len(cur_input_tokens) < max_seq_len or len(cur_output_tokens) < max_seq_len:\n",
    "                input_tokens.extend(cur_input_tokens)\n",
    "                output_tokens.extend(cur_output_tokens)\n",
    "                \n",
    "                # 添加 PAD 符号使每个序列等长，长度为 max_seq_len\n",
    "                while len(cur_input_tokens) < max_seq_len:\n",
    "                    cur_input_tokens.append(PAD)\n",
    "                    # 把输出也填充到了最大长度\n",
    "                    cur_output_tokens.append(PAD)\n",
    "                    \n",
    "                input_seqs.append(cur_input_tokens)                            \n",
    "                output_seqs.append(cur_output_tokens)\n",
    "                \n",
    "            else:\n",
    "                cur_input_tokens = cur_input_tokens[0: max_seq_len]\n",
    "                cur_output_tokens = cur_output_tokens[0: max_seq_len]\n",
    "                \n",
    "                input_tokens.extend(cur_input_tokens)\n",
    "                input_seqs.append(cur_input_tokens)\n",
    "                \n",
    "                output_tokens.extend(cur_output_tokens)\n",
    "                output_seqs.append(cur_output_tokens)\n",
    "                \n",
    "        fr_vocab = text.vocab.Vocabulary(collections.Counter(input_tokens), reserved_tokens=[PAD])\n",
    "        en_vocab = text.vocab.Vocabulary(collections.Counter(output_tokens), reserved_tokens=[PAD])\n",
    "    \n",
    "    return fr_vocab, en_vocab, input_seqs, output_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vocab, output_vocab, input_seqs, output_seqs = read_data(max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215541"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<PAD>', 'N', 'C', 'B', 'E', 'I', '']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_vocab.idx_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = nd.zeros((len(input_seqs), max_seq_len))\n",
    "# Y = nd.zeros((len(output_seqs), max_seq_len))\n",
    "\n",
    "# for i in range(len(input_seqs)):\n",
    "#     X[i] = nd.array(input_vocab.to_indices(input_seqs[i]))\n",
    "#     Y[i] = nd.array(output_vocab.to_indices(output_seqs[i]))\n",
    "# np.save(\"../data_for_mul-rnn/X.npy\", X.asnumpy())\n",
    "# np.save(\"../data_for_mul-rnn/Y.npy\", Y.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"../data_for_mul-rnn/X.npy\") and  os.path.exists(\"../data_for_mul-rnn/Y.npy\"):\n",
    "    print(\"Loading...\")\n",
    "    X = np.load(\"../data_for_mul-rnn/X.npy\")\n",
    "    Y = np.load(\"../data_for_mul-rnn/Y.npy\")\n",
    "    print(\"End\")\n",
    "else:\n",
    "    print(\"Converting...\")\n",
    "    X = nd.zeros((len(input_seqs), max_seq_len))\n",
    "    Y = nd.zeros((len(output_seqs), max_seq_len))\n",
    "\n",
    "    for i in range(len(input_seqs)):\n",
    "        X[i] = nd.array(input_vocab.to_indices(input_seqs[i]))\n",
    "        Y[i] = nd.array(output_vocab.to_indices(output_seqs[i]))\n",
    "    np.save(\"../data_for_mul-rnn/X.npy\", X.asnumpy())\n",
    "    np.save(\"../data_for_mul-rnn/Y.npy\", Y.asnumpy())\n",
    "    print(\"End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((386560, 50), (386560, 50)), ((42952, 50), (42952, 50)))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=33)\n",
    "((X_train.shape, Y_train.shape), (X_test.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = gluon.data.ArrayDataset(nd.array(X_train, ctx=ctx), nd.array(Y_train, ctx=ctx))\n",
    "data_iter_train = gluon.data.DataLoader(dataset_train, batch_size, shuffle=True, last_batch='rollover')\n",
    "\n",
    "dataset_test = gluon.data.ArrayDataset(nd.array(X_test, ctx=ctx), nd.array(Y_test, ctx=ctx))\n",
    "data_iter_test = gluon.data.DataLoader(dataset_test, batch_size, shuffle=True, last_batch='rollover')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding = text.embedding.create('fasttext', pretrained_file_name='wiki.zh.vec', vocabulary=input_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(input_vocab))\n",
    "# print(len(embedding))\n",
    "# print(embedding.to_indices([PAD, '中国']))\n",
    "# print(input_vocab.to_indices([PAD, '中国']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mul_Layers_Bid_GRU(Block):\n",
    "    def __init__(self, hidden_dim, input_dim, dense_hidden_dim, output_dim, num_layers, drop_prob):\n",
    "        super(Mul_Layers_Bid_GRU, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.dense_hidden_dim = dense_hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.drop_prob = drop_prob\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.rnn = rnn.GRU(hidden_dim, num_layers, dropout=drop_prob, bidirectional=True)\n",
    "        \n",
    "        self.dense_hidden = nn.Dense(dense_hidden_dim, activation='relu', flatten=False)\n",
    "        self.out = nn.Dense(output_dim, flatten=False)\n",
    "        \n",
    "    def forward(self, inputs, states):\n",
    "        # states 是一个列表\n",
    "        # inputs尺寸: (batch_size, num_steps)，emb尺寸: (num_steps, batch_size, 300)\n",
    "        batch_size = inputs.shape[0]\n",
    "        num_steps = inputs.shape[1]\n",
    "        \n",
    "        emb = self.embedding(inputs).swapaxes(0, 1)\n",
    "        emb = self.dropout(emb)\n",
    "        \n",
    "        # hidden_output 尺寸：(num_steps, batch_size, 2*hidden_dim)\n",
    "        # state 尺寸: (2*num_layers, batch_size, hidden_dim)      \n",
    "        hidden_output, bid_state = self.rnn(emb, states[0])\n",
    "        \n",
    "        # hidden_output shape: (num_steps, batch_size, 2*hidden_dim)\n",
    "        # 转变为 （batch_size, num_steps, 2*hidden_dim)\n",
    "        hidden_output = hidden_output.swapaxes(0, 1)\n",
    "        hidden_output = self.dropout(hidden_output)\n",
    "        \n",
    "        # dense_hidden_output shape: (batch_size, num_steps, dense_hidden_dim)\n",
    "        dense_hidden_output = self.dense_hidden(hidden_output)\n",
    "        dense_hidden_output = self.dropout(dense_hidden_output)\n",
    "               \n",
    "        # output shape: (batch_size, num_steps, output_dim)\n",
    "        output = self.out(dense_hidden_output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def begin_state(self, *args, **kwargs):\n",
    "        return self.rnn.begin_state(*args, **kwargs)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_value = nd.array(list(output_vocab.token_to_idx.values()), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_one_hot = nd.one_hot(dic_value, dic_value.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
       " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
       " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
       " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
       " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
       " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
       " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
       " [0. 0. 0. 0. 0. 0. 0. 1.]]\n",
       "<NDArray 8x8 @gpu(0)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
       " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
       " [0. 0. 0. 0. 1. 0. 0. 0.]]\n",
       "<NDArray 3x8 @gpu(0)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd.take(label_one_hot, nd.array([0, 2, 4], ctx=ctx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<PAD>', 'N', 'C', 'B', 'E', 'I', '']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_vocab.idx_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_scores(y_hat, label):\n",
    "    \"\"\"y_hat 与 label 都为一维向量\"\"\"\n",
    "    p = metrics.precision_score(label, y_hat, average=None)\n",
    "    r = metrics.recall_score(label, y_hat, average=None)\n",
    "    f1 = metrics.recall_score(label, y_hat, average=None)\n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, max_seq_len, label_one_hot, output_vocab, learning_rate, ctx):\n",
    "    # 对于三个网络，分别初始化它们的模型参数并定义它们的优化器。\n",
    "    model.collect_params().initialize(mx.init.Xavier(), ctx=ctx)\n",
    "    \n",
    "    optimizer = gluon.Trainer(model.collect_params(), 'adam',\n",
    "                                      {'learning_rate': learning_rate})\n",
    "\n",
    "    softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss(sparse_label=False)\n",
    "\n",
    "    prev_time = datetime.datetime.now()\n",
    "    \n",
    "    total_loss = []\n",
    "    total_p = []\n",
    "    total_r = []\n",
    "    total_f1 = []\n",
    "    \n",
    "    for epoch in range(0, epochs):\n",
    "        epoch_loss = 0.0\n",
    "        preds = []\n",
    "        trues = []\n",
    "        batch_idx = 0\n",
    "        for x, y in data_iter_train:\n",
    "            with autograd.record():\n",
    "                batch_loss = nd.array([0], ctx=ctx)\n",
    "                state = model.begin_state(\n",
    "                    func=mx.nd.zeros, batch_size=batch_size, ctx=ctx)\n",
    "                \n",
    "                # outputs shape: (batch_size, num_step, output_dim)\n",
    "                outputs = model(x, state)\n",
    "                # label shape: (batch_size, num_step, output_dim)\n",
    "                label = nd.take(label_one_hot, y)\n",
    "                batch_loss = nd.mean(softmax_cross_entropy(outputs, label))\n",
    "                \n",
    "            batch_loss.backward()\n",
    "            optimizer.step(batch_size)\n",
    "            \n",
    "            epoch_loss += batch_loss.asscalar()       \n",
    "            \n",
    "            # pred_outputs shape: (batch_size, num_step)\n",
    "            pred_outputs = nd.argmax(nd.softmax(outputs, axis=2), axis=2)    \n",
    "            \n",
    "            preds.append(pred_outputs)\n",
    "            trues.append(y)\n",
    "            \n",
    "            # print(pred_outputs.shape)           \n",
    "            \n",
    "            if batch_idx % 500 == 0:\n",
    "#                 batch_p, batch_r, batch_f1 = cal_scores(pred_outputs.reshape((-1,)).asnumpy(), y.reshape((-1,)).asnumpy())\n",
    "                print(\"epoch: {0} , batch: {1}, batch_loss: {2}\".format(epoch, batch_idx, batch_loss.asscalar()))\n",
    "#                 print(\"batch_p: {0}\".format(batch_p))\n",
    "#                 print(\"batch_r: {0}\".format(batch_r))\n",
    "#                 print(\"batch_f1: {0}\".format(batch_f1))\n",
    "                for idx in range(2): \n",
    "                    true_idx = [int(x) for x in list(y[idx].asnumpy())]\n",
    "                    pred_idx = [int(x) for x in list(pred_outputs[idx].asnumpy())]\n",
    "                    \n",
    "                    true_label = output_vocab.to_tokens(true_idx)\n",
    "                    pred_label = output_vocab.to_tokens(pred_idx)\n",
    "                    \n",
    "                    print(\"Sapmle {0} :\".format(idx))\n",
    "                    print(\"True label : {0}\".format(true_label))\n",
    "                    print(\"Pred label : {0}\".format(pred_label))\n",
    "            batch_idx += 1\n",
    "            \n",
    "        \n",
    "        epoch_loss = epoch_loss / batch_idx\n",
    "        \n",
    "        cal_score_pred = nd.concat(*preds, dim=0).reshape((-1,)).asnumpy()\n",
    "        cal_score_true = nd.concat(*trues, dim=0).reshape((-1,)).asnumpy()\n",
    "        \n",
    "        epoch_p, epoch_r, epoch_f1 = cal_scores(cal_score_pred, cal_score_true)\n",
    "        \n",
    "        total_loss.append(epoch_loss)\n",
    "        total_p.append(epoch_p)\n",
    "        total_r.append(epoch_r)\n",
    "        total_f1.append(epoch_f1)\n",
    "        \n",
    "        print(\"epoch: {0} , epoch_loss: {1}\".format(epoch, epoch_loss))\n",
    "        print(\"epoch_p: {0}\".format(epoch_p))\n",
    "        print(\"epoch_r: {0}\".format(epoch_r))\n",
    "        print(\"epoch_f1: {0}\".format(epoch_f1))\n",
    "        print(\"-----------------------------------------------------\")\n",
    "    \n",
    "    plt.plot(range(epochs), total_loss)\n",
    "    plt.show()\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mul_Layers_Bid_GRU(hidden_dim, len(input_vocab), dense_hidden_dim, len(output_vocab), num_layers, drop_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 , batch: 0, batch_loss: 2.0801637172698975\n",
      "Sapmle 0 :\n",
      "True label : ['C', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Pred label : ['', '<unk>', '', '', '<unk>', '<unk>', '', '', 'I', '<unk>', '', '', 'E', '<PAD>', '<unk>', '', '', '', 'N', 'N', '', 'I', '', '<PAD>', '<unk>', '', '', '', '', '', 'C', '', '<unk>', '', '', '', 'E', 'E', '', '<unk>', '', 'E', 'I', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'N', 'E']\n",
      "Sapmle 1 :\n",
      "True label : ['C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Pred label : ['', '<unk>', '', 'C', '', '<unk>', '<unk>', '<PAD>', '', 'E', '<unk>', '<PAD>', '<unk>', '', '', '', 'E', '<PAD>', 'E', 'N', '<unk>', '', 'E', '', '', '<unk>', '<unk>', '<unk>', '<unk>', '', '<unk>', '', '', '<unk>', '<unk>', '<unk>', '', '<unk>', '<unk>', '<unk>', '<unk>', 'E', '<unk>', '<unk>', 'N', 'N', '<unk>', '<unk>', '<unk>', '<unk>']\n",
      "epoch: 0 , batch: 500, batch_loss: 0.4356721043586731\n",
      "Sapmle 0 :\n",
      "True label : ['C', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['C', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Pred label : ['N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "epoch: 0 , batch: 1000, batch_loss: 0.39992672204971313\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'B', 'E', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'C', 'C', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'I', 'N', 'N', 'N', 'N', 'B', 'I', 'I', 'E', 'N']\n",
      "Pred label : ['N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 0 , batch: 1500, batch_loss: 0.3234182894229889\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'B', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'N', 'E', 'N', 'N', 'N', 'N', 'N', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'B', 'I', 'E', 'B']\n",
      "Pred label : ['N', 'N', 'C', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'B', 'E', 'B', 'E', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\developtool\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 , epoch_loss: 0.4229380942535716\n",
      "epoch_p: [0.         0.99541995 0.8377669  0.52707297 0.23717097 0.12206409\n",
      " 0.03227771 0.        ]\n",
      "epoch_r: [0.00000000e+00 9.95905007e-01 9.89373188e-01 2.47643383e-01\n",
      " 4.00598802e-03 2.15136499e-03 3.05148371e-04 0.00000000e+00]\n",
      "epoch_f1: [0.00000000e+00 9.95905007e-01 9.89373188e-01 2.47643383e-01\n",
      " 4.00598802e-03 2.15136499e-03 3.05148371e-04 0.00000000e+00]\n",
      "-----------------------------------------------------\n",
      "epoch: 1 , batch: 0, batch_loss: 0.3241179585456848\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Sapmle 1 :\n",
      "True label : ['C', 'N', 'N', 'N', 'B', 'I', 'I', 'I', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'C', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'C', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N']\n",
      "epoch: 1 , batch: 500, batch_loss: 0.2875917851924896\n",
      "Sapmle 0 :\n",
      "True label : ['C', 'C', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Pred label : ['C', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Pred label : ['C', 'N', 'C', 'N', 'B', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "epoch: 1 , batch: 1000, batch_loss: 0.261854887008667\n",
      "Sapmle 0 :\n",
      "True label : ['C', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Pred label : ['C', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 1 , batch: 1500, batch_loss: 0.23228660225868225\n",
      "Sapmle 0 :\n",
      "True label : ['C', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N']\n",
      "Pred label : ['C', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['B', 'E', 'N', 'B', 'E', 'N', 'B', 'E', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'B', 'E', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'B', 'I']\n",
      "Pred label : ['B', 'E', 'N', 'B', 'C', 'N', 'B', 'E', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 1 , epoch_loss: 0.26903072949868956\n",
      "epoch_p: [0.99986489 0.89413331 0.67269445 0.52012081 0.50255647 0.36723121\n",
      " 0.88888889]\n",
      "epoch_r: [0.9999328  0.98031571 0.8282731  0.12477994 0.13204888 0.05630275\n",
      " 0.20512821]\n",
      "epoch_f1: [0.9999328  0.98031571 0.8282731  0.12477994 0.13204888 0.05630275\n",
      " 0.20512821]\n",
      "-----------------------------------------------------\n",
      "epoch: 2 , batch: 0, batch_loss: 0.21792230010032654\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'C', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'B', 'E', 'N', 'N', 'B', 'E', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'C', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'C', 'N', 'B', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E']\n",
      "Pred label : ['N', 'N', 'C', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'C', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 2 , batch: 500, batch_loss: 0.2310517430305481\n",
      "Sapmle 0 :\n",
      "True label : ['C', 'C', 'B', 'E', 'N', 'N', 'C', 'N', 'N', 'N', 'C', 'C', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'B', 'E', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['C', 'C', 'B', 'E', 'N', 'N', 'C', 'N', 'N', 'N', 'C', 'C', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 , batch: 1000, batch_loss: 0.1683739721775055\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'C', 'N', 'E', 'B', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'C', 'E', 'N', 'N', 'N', 'C', 'N', 'B', 'E', 'N', 'N', 'N', 'C', 'N', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'C', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'C', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "epoch: 2 , batch: 1500, batch_loss: 0.1949334740638733\n",
      "Sapmle 0 :\n",
      "True label : ['C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Pred label : ['C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'N', 'N', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'C', 'C', 'N', 'N', 'N', 'C', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'I', 'E', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'C', 'B', 'E', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'I', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 2 , epoch_loss: 0.20564865769929444\n",
      "epoch_p: [0.99996172 0.91781634 0.79866625 0.64008707 0.65672771 0.5439223\n",
      " 0.91176471]\n",
      "epoch_r: [0.99996824 0.97453739 0.90191254 0.32750898 0.35792681 0.25696372\n",
      " 0.79487179]\n",
      "epoch_f1: [0.99996824 0.97453739 0.90191254 0.32750898 0.35792681 0.25696372\n",
      " 0.79487179]\n",
      "-----------------------------------------------------\n",
      "epoch: 3 , batch: 0, batch_loss: 0.15267160534858704\n",
      "Sapmle 0 :\n",
      "True label : ['B', 'E', 'N', 'C', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Pred label : ['B', 'E', 'N', 'C', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "epoch: 3 , batch: 500, batch_loss: 0.17479807138442993\n",
      "Sapmle 0 :\n",
      "True label : ['B', 'E', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Pred label : ['C', 'C', 'N', 'N', 'N', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Sapmle 1 :\n",
      "True label : ['C', 'C', 'N', 'B', 'I', 'E', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Pred label : ['C', 'C', 'N', 'N', 'N', 'E', 'N', 'N', 'N', 'E', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "epoch: 3 , batch: 1000, batch_loss: 0.15951590240001678\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Sapmle 1 :\n",
      "True label : ['C', 'B', 'E', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'E', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'C', 'N', 'N']\n",
      "Pred label : ['C', 'B', 'E', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'C', 'N', 'N']\n",
      "epoch: 3 , batch: 1500, batch_loss: 0.17036280035972595\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Pred label : ['N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 , epoch_loss: 0.17291794000871924\n",
      "epoch_p: [0.9999776  0.93030695 0.86656917 0.69776518 0.71152027 0.64171744\n",
      " 0.75      ]\n",
      "epoch_r: [0.99997774 0.97598269 0.92017757 0.4365524  0.47105506 0.38809115\n",
      " 0.69230769]\n",
      "epoch_f1: [0.99997774 0.97598269 0.92017757 0.4365524  0.47105506 0.38809115\n",
      " 0.69230769]\n",
      "-----------------------------------------------------\n",
      "epoch: 4 , batch: 0, batch_loss: 0.1607147455215454\n",
      "Sapmle 0 :\n",
      "True label : ['C', 'B', 'I', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'C', 'N', 'N', 'C', 'C', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'B', 'E', '<PAD>', '<PAD>']\n",
      "Pred label : ['C', 'C', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'C', 'N', 'N', 'C', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'B', 'N', 'B', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "epoch: 4 , batch: 500, batch_loss: 0.14537228643894196\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Pred label : ['N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "epoch: 4 , batch: 1000, batch_loss: 0.16224806010723114\n",
      "Sapmle 0 :\n",
      "True label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'B', 'E', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N']\n",
      "Pred label : ['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'E', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Sapmle 1 :\n",
      "True label : ['C', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'C', 'C', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'C', 'N']\n",
      "Pred label : ['C', 'N', 'N', 'C', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'B', 'E', 'B', 'E', 'N', 'N', 'N', 'C', 'N', 'N', 'N', 'N', 'C', 'C', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'C', 'N']\n",
      "epoch: 4 , batch: 1500, batch_loss: 0.13609099388122559\n",
      "Sapmle 0 :\n",
      "True label : ['B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'B', 'E', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Pred label : ['B', 'E', 'B', 'I', 'N', 'I', 'E', 'N', 'N', 'N', 'C', 'N', 'B', 'E', 'N', 'C', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Sapmle 1 :\n",
      "True label : ['N', 'C', 'N', 'C', 'N', 'N', 'C', 'N', 'C', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Pred label : ['N', 'C', 'N', 'C', 'N', 'N', 'C', 'N', 'C', 'N', 'N', 'N', 'N', 'B', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "epoch: 4 , epoch_loss: 0.1550648796834693\n",
      "epoch_p: [0.9999837  0.93725451 0.89233464 0.72824135 0.74588767 0.68544346\n",
      " 1.        ]\n",
      "epoch_r: [0.99998483 0.9774615  0.93064219 0.49348054 0.52809701 0.45839619\n",
      " 0.94871795]\n",
      "epoch_f1: [0.99998483 0.9774615  0.93064219 0.49348054 0.52809701 0.45839619\n",
      " 0.94871795]\n",
      "-----------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(model, max_seq_len, label_one_hot, output_vocab, learning_rate, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(shape=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_scores(y_hat, label):\n",
    "    \"\"\"y_hat 与 label 都为一维向量\"\"\"\n",
    "    p = metrics.precision_score(label, y_hat, average=None)\n",
    "    r = metrics.recall_score(label, y_hat, average=None)\n",
    "    f1 = metrics.recall_score(label, y_hat, average=None)\n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 0, 1, 0, 0],\n",
    "              [1, 2, 0, 1, 0]\n",
    "             ])\n",
    "b = np.array([[1, 0, 1, 1, 0],\n",
    "              [1, 1, 1, 0, 1]\n",
    "             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\developtool\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.4 , 0.75, 0.  ]),\n",
       " array([0.66666667, 0.42857143, 0.        ]),\n",
       " array([0.66666667, 0.42857143, 0.        ]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_scores(a.reshape(-1), b.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
